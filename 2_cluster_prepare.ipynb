{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f36d6a4",
   "metadata": {},
   "source": [
    "# Clustering Proteins and Data Integration\n",
    "# 1. Introduction\n",
    "\n",
    "# 2. Preparing and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645b30b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install kneed'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install kneed'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a547a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_8887/143084480.py\", line 19, in <module>\n",
      "    import torch\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Data processing and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Standard library imports\n",
    "import ast\n",
    "import subprocess\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import re\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.metrics import silhouette_score\n",
    "from kneed import KneeLocator\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import to_rgba, LinearSegmentedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import kaleido\n",
    "\n",
    "# Machine learning and statistical analysis\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import umap\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import spearmanr, kruskal, mannwhitneyu\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import shap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "# Utility libraries\n",
    "import gzip\n",
    "import random\n",
    "from natsort import natsorted\n",
    "from typing import Dict, List, Tuple, Set, Optional\n",
    "import gc\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "\n",
    "# Dash\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, callback, State\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Own Scoring system\n",
    "import corrosion_scoring as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca72e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local (VSCode) environment\n"
     ]
    }
   ],
   "source": [
    "# Determine the environment\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Running in Google Colab environment\")\n",
    "    # for colab\n",
    "    base_dir = Path(\"/content/drive/MyDrive/MIC\")\n",
    "    abundance_excel = base_dir / \"data_picrust/merged_to_sequence.xlsx\"\n",
    "    output_large = base_dir / \"output_large\"\n",
    "    output_base = base_dir\n",
    "    market_dir = base_dir / \"output_large\" \n",
    "    #Directory to keep some Results\n",
    "    large_dir = base_dir / \"2_Micro/data_visual\"\n",
    "    large_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "elif Path(\"/kaggle\").exists():\n",
    "    print(\"Running in Kaggle environment\")\n",
    "    # For Kaggle work# Input datasets (read-only in Kaggle) \n",
    "    base_dir = Path(\"/kaggle/input/\")  \n",
    "    abundance_excel = base_dir / \"new-picrust/merged_to_sequence.xlsx\" \n",
    "    #Input physicochemical variables\n",
    "    data_physicochemical = base_dir / \"physicochemical-parameters/Physicochemical.xlsx\"\n",
    "    combined_input = base_dir  / \"combined_markers.xlsx\"\n",
    "    #===============================================\n",
    "    #Directory to keep  Results\n",
    "    output_base = Path(\"/kaggle/working/\")\n",
    "    shared_dir = output_base/\"Visualisations\"\n",
    "    shared_dir.mkdir(parents=True, exist_ok=True)\n",
    "    combined_path = output_base / \"combined_markers.xlsx\"\n",
    "      \n",
    "else:\n",
    "    print(\"Running in local (VSCode) environment\")\n",
    "    base_dir = Path(\"data\")\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Base Paths for local environment\n",
    "    abundance_excel = base_dir / \"merged_to_sequence.xlsx\"\n",
    "    #Input physicochemical variables8ikk                           ´\n",
    "    data_physicochemical = Path(\"/home/beatriz/MIC/1_Physicochemical/Data/Physicochemical.xlsx\")\n",
    "    #================================================\n",
    "    # This files are too large for github and are store on Kaggle for educational purposes\n",
    "    output_large = Path(\"/home/beatriz/MIC/output_large\")\n",
    "    output_base = base_dir \n",
    "    #Directory to keep some Results\n",
    "    shared_dir= Path(\"/home/beatriz/SharedFolder/Visualisations/\")\n",
    "    combined_path = base_dir / \"combined_markers.xlsx\"\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc808b5",
   "metadata": {},
   "source": [
    "### Importing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf81ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physicochemical data data from notebook 8 repo 1_Physicochemical\n",
    "all_physichem = pd.read_excel(data_physicochemical, sheet_name='all_physicochemical', engine ='openpyxl')\n",
    "# Microbiological Data from notebook 6 repo 2_Micro.\n",
    "df_proteins= pd.read_excel(combined_path, sheet_name='df_proteins',  engine ='openpyxl')\n",
    "#mapping of genera to site from the original df for validation\n",
    "genus_site_df = pd.read_excel(combined_path, sheet_name='genus_to_sites', engine ='openpyxl')\n",
    "# All markers after pattern, integration, classification, increasing, and balance functions\n",
    "balanced_markers= pd.read_excel(combined_path, sheet_name='balanced_markers', engine ='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040495c",
   "metadata": {},
   "source": [
    "# 3 Functional Category groups and Random Forest importance\n",
    "Using functional Category groups and Random Forest importance to select top markers.This rf integrates the functional categories from the cs package, uses Random Forest to identify the most important features for predicting corrosion risk and groups them by functional category to understand which biological processes are most informative, but also an additional step will communicate the niche specific processes. Then uses SHAP values for more interpretable feature importance. At end a selected balanced set of features representing different functional categories is chosen mapping the features back to specific proteins for biological interpretation.\n",
    "The chosen column to be associating the data or to serve as integration factor was the \"functional_categories\" or \"fc_present\" both of which presented similar entries and it was finally decided to cluster instead according to the \"niche_specific_pathways\" the reason is because the granularity it contains more differentiation between proteins already very similar all being at this point mostly on category 3. The functional_category, corrosion_mechanisms, enzyme_class and explanation columns are also brough forward to have the richness of the information. Additionally Columns Sites, Categories, combined_score, protein_name and genus would be also brought. \n",
    "\n",
    "The results from the function analyze_protein_hierachy gives a comprehensive dataframe. This is a single flattened DataFrame combining both descriptive and explanatory metadata and numerical attributes those are:  \n",
    "* Fields that support interpretation and discussion of each protein:  \n",
    " ['Sites', 'protein_name', 'genera_count', 'genera', 'functional_categories', 'niche_pathways', 'enzyme_class', 'corrosion_mechanisms',  'explanation', 'combined_score']\n",
    "* Fields that with values that feed a supervised neural network in Notebook 2:  \n",
    "['Sites','Category','protein_name', norm_abund_contri', 'fold_change_2vs1', 'log2fc_2vs1', 'fold_change_3vs2', 'log2fc_3vs2', 'fold_change_3vs1', 'log2fc_3vs1',  'specificity', 'prevalence', 'max_abs_log2fc', 'combined_score'] \n",
    "The idea of the operation is to mantain the original relationships so hat each row represents one unique (protein-genus-site) observation preserving the original abundance granularity from the PICRUSTt2  OTU→EC→protein mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f092d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_protein_hierarchy_rf(protein_df, n_estimators=100, n_top_proteins=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Analyzes protein hierarchy using Random Forest for feature importance,\n",
    "    performs hierarchical clustering on niche-specific pathways,\n",
    "    and returns a comprehensive DataFrame with both descriptive and numerical attributes.\n",
    "    \n",
    "    Parameters: protein_df : DataFrame Input DataFrame containing protein data with all required columns\n",
    "    n_estimators : int, default=100   Number of trees in the Random Forest\n",
    "    n_top_proteins : int, default=50  Number of top proteins to select based on importance\n",
    "    random_state : int, default=42  Random seed for reproducibility\n",
    "    \n",
    "    Returns:  DataFrame  Comprehensive DataFrame with selected proteins and all required attributes\n",
    "    \"\"\"\n",
    "    # Step 1: Prepare data for Random Forest: features for importance ranking (numerical columns)\n",
    "    numerical_features = ['fold_change_2vs1', 'log2fc_2vs1', 'fold_change_3vs2', 'log2fc_3vs2', 'fold_change_3vs1', 'log2fc_3vs1', \n",
    "                         'specificity', 'prevalence', 'max_abs_log2fc', 'combined_score']\n",
    "    \n",
    "    # Create dummy target for feature importance using 'Category' as a proxy target\n",
    "    X = protein_df[numerical_features].fillna(0)\n",
    "    y = protein_df['Category']\n",
    "    \n",
    "    # Step 2: Train Random Forest for feature importance    \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Step 3: Calculate SHAP values for feature importance interpretation\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # Average across samples\n",
    "    sample_averaged = np.mean(shap_values, axis=0)  # Shape: (10, 3)\n",
    "\n",
    "    # Take absolute values\n",
    "    absolute_values = np.abs(sample_averaged)  # Still (10, 3)\n",
    "\n",
    "    # Average across classes to get a single importance score per feature\n",
    "    shap_importance = np.mean(absolute_values, axis=1)  # Final shape: (10,)\n",
    "\n",
    "    # Create feature importance DataFrame\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': numerical_features,\n",
    "        'importance': rf.feature_importances_,\n",
    "        'shap_importance': shap_importance\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('shap_importance', ascending=False)\n",
    "    #======================================================\n",
    "    # Step 4: Hierarchical clustering based on niche-specific pathways\n",
    "    # First, create a distance matrix from the pathway information: Convert niche-specific pathways to a TF-IDF matrix\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # Handle missing values\n",
    "    pathway_texts = protein_df['niche_specific_pathways'].fillna('')\n",
    "    pathway_matrix = tfidf.fit_transform(pathway_texts)\n",
    "    \n",
    "    # Compute hierarchical clustering\n",
    "    Z = linkage(pathway_matrix.toarray(), method='ward')\n",
    "    \n",
    "    # Determine optimal number of clusters compute different clustering solutions\n",
    "    max_clusters = min(20, len(protein_df))\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for n_clusters in range(2, max_clusters + 1):\n",
    "        clusters = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "        if len(np.unique(clusters)) <= 1:\n",
    "            silhouette_scores.append(0)\n",
    "        else:\n",
    "            silhouette_scores.append(silhouette_score(pathway_matrix.toarray(), clusters))\n",
    "    \n",
    "    # Find optimal number of clusters using knee point detection\n",
    "    kl = KneeLocator(range(2, max_clusters + 1), silhouette_scores, \n",
    "                    curve='concave', direction='increasing')\n",
    "    optimal_clusters = kl.elbow if kl.elbow else 5  # Default to 5 if no clear elbow\n",
    "    \n",
    "    # Assign clusters\n",
    "    clusters = fcluster(Z, optimal_clusters, criterion='maxclust')\n",
    "    protein_df['pathway_cluster'] = clusters\n",
    "    \n",
    "    # Step 5: Evaluate protein importance within functional categories\n",
    "    # Add importance to original dataframe\n",
    "    protein_importance = {}\n",
    "    for idx, row in protein_df.iterrows():\n",
    "        protein_name = row['protein_name']\n",
    "        protein_importance[protein_name] = protein_importance.get(protein_name, 0)\n",
    "        \n",
    "        # Calculate importance based on the SHAP values of numerical features\n",
    "        for i, feature in enumerate(numerical_features):\n",
    "            if not pd.isna(row[feature]):\n",
    "                feature_weight = feature_importance.loc[\n",
    "                    feature_importance['feature'] == feature, 'shap_importance'].values[0]\n",
    "                protein_importance[protein_name] += row[feature] * feature_weight\n",
    "    \n",
    "    # Create a DataFrame with protein importance\n",
    "    protein_importance_df = pd.DataFrame({\n",
    "        'protein_name': list(protein_importance.keys()),\n",
    "        'importance_score': list(protein_importance.values())\n",
    "    }).sort_values('importance_score', ascending=False)\n",
    "    \n",
    "    # Step 6: Select a balanced set of top proteins. First, group by functional categories\n",
    "    fc_grouped = protein_df.groupby('functional_categories_present')\n",
    "    \n",
    "    # Select top proteins from each functional category\n",
    "    selected_proteins = []\n",
    "    for fc, group in fc_grouped:\n",
    "        # Get proteins in this functional category\n",
    "        fc_proteins = group['protein_name'].unique()\n",
    "        \n",
    "        # Get importance scores for these proteins\n",
    "        fc_importance = protein_importance_df[\n",
    "            protein_importance_df['protein_name'].isin(fc_proteins)\n",
    "        ]\n",
    "        \n",
    "        # Select top proteins from this category (proportional to category size)\n",
    "        n_select = max(1, int(len(fc_proteins) * n_top_proteins / len(protein_df['protein_name'].unique())))\n",
    "        top_fc_proteins = fc_importance.head(n_select)['protein_name'].tolist()\n",
    "        selected_proteins.extend(top_fc_proteins)\n",
    "    \n",
    "    # Step 7: Create and return the comprehensive DataFrame and filter to selected proteins\n",
    "    comprehensive_df = protein_df[protein_df['protein_name'].isin(selected_proteins)]\n",
    "    \n",
    "    # Add group count information\n",
    "    genera_counts = comprehensive_df.groupby('protein_name')['Genus'].nunique().reset_index()\n",
    "    genera_counts.columns = ['protein_name', 'genera_count']\n",
    "    \n",
    "    genera_lists = comprehensive_df.groupby('protein_name')['Genus'].apply(list).reset_index()\n",
    "    genera_lists.columns = ['protein_name', 'genera']\n",
    "    \n",
    "    # Merge with comprehensive_df\n",
    "    comprehensive_df = comprehensive_df.merge(genera_counts, on='protein_name', how='left')\n",
    "    comprehensive_df = comprehensive_df.merge(genera_lists, on='protein_name', how='left')\n",
    "    \n",
    "    # Add importance scores\n",
    "    comprehensive_df = comprehensive_df.merge(\n",
    "        protein_importance_df[['protein_name', 'importance_score']], \n",
    "        on='protein_name', how='left'\n",
    "    )\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    comprehensive_df = comprehensive_df.rename(columns={\n",
    "        'niche_specific_pathways': 'niche_pathways'\n",
    "    })\n",
    "    \n",
    "    # Ensure all required columns are present\n",
    "    descriptive_fields = ['Sites', 'protein_name', 'genera_count', 'genera', \n",
    "                         'functional_categories', 'niche_pathways', 'enzyme_class', \n",
    "                         'corrosion_mechanisms', 'explanation', 'combined_score']\n",
    "    \n",
    "    numerical_fields = ['Sites', 'Category', 'protein_name', 'norm_abund_contri',\n",
    "                       'fold_change_2vs1', 'log2fc_2vs1', 'fold_change_3vs2', \n",
    "                       'log2fc_3vs2', 'fold_change_3vs1', 'log2fc_3vs1', \n",
    "                       'specificity', 'prevalence', 'max_abs_log2fc', 'combined_score']\n",
    "    \n",
    "    # Select columns for final output\n",
    "    all_required_fields = list(set(descriptive_fields + numerical_fields))\n",
    "    output_columns = [col for col in all_required_fields if col in comprehensive_df.columns]\n",
    "    \n",
    "    # Add importance score and cluster information\n",
    "    output_columns += ['importance_score', 'pathway_cluster']\n",
    "    \n",
    "    return comprehensive_df[output_columns]\n",
    "\n",
    "protein_hierarchy = analyze_protein_hierarchy_rf(df_proteins, n_estimators=100, n_top_proteins=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70283b9a",
   "metadata": {},
   "source": [
    "The protein_hierarchy dataframe seem a good mixture of numerical and descriptive parameters, however the genera count appear no to reflect that the protein corresponds to a substantial genera prevalence, due to that, genera count sort the genera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1785b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['enoyl-[ reductase [ (ec 1.3.1.9)',\n",
       "       '3-oxoacyl-[ reductase (ec 1.1.1.100)',\n",
       "       'enoyl-[ reductase (nadph, si-specific); acyl-acp-dehydrogenase',\n",
       "       'glutathione hydrolase proenzyme (ec 2.3.2.2) 3.4.19',\n",
       "       'gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (glutamine',\n",
       "       'glutamine-dependent nad(+) synthetase (ec 6.3.5.1)',\n",
       "       'aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate',\n",
       "       'phosphoenolpyruvate carboxykinase [ (pep carboxykinase',\n",
       "       'aspartate transaminase; glutamic-oxaloacetic transaminase;',\n",
       "       'dna ligase (ec 6.5.1.2) (polydeoxyribonucleotide-synthase',\n",
       "       \"holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7) (4'\",\n",
       "       'enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl',\n",
       "       'bifunctional enzyme ispd-ispf [',\n",
       "       'ferredoxin---nadp+ reductase; ferredoxin-nicotinamide'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_hierarchy= protein_hierarchy.sort_values('genera_count', ascending=False).head(200).copy()\n",
    "protein_hierarchy[\"protein_name\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715bb2d",
   "metadata": {},
   "source": [
    "## Data for Descriptive Table\n",
    "In this table the protein_names would be agrupated so that all the other descriptives would be aggregated to visualise the whole data. On the other hand the dataframe with the whole result protein_hierarchi which was ordered by genera count is brough to the next step namely the pca to visualise the natural patterns of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f54d1b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    combined_score  \\\n",
      "protein_name                                                         \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                         53.668974   \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                     53.655383   \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...       53.143900   \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....       53.203451   \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...       52.725787   \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)       52.708479   \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate       52.442570   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...       53.070554   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...       52.688025   \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...       52.123479   \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl       53.549363   \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...       52.633479   \n",
      "bifunctional enzyme ispd-ispf [                          52.697201   \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...       54.543951   \n",
      "\n",
      "                                                    genera_count  \\\n",
      "protein_name                                                       \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                            1225   \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                         841   \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...           729   \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....           256   \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...           169   \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)           144   \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate           121   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...           121   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...           121   \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...           100   \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl            81   \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...            81   \n",
      "bifunctional enzyme ispd-ispf [                               32   \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...            24   \n",
      "\n",
      "                                                                                               genera  \\\n",
      "protein_name                                                                                            \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                    [Methylocystis, Prevotella, Flavisolibacter, D...   \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                [Prevotella, Flavisolibacter, Opitutus, Desulf...   \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...  [Prevotella, Flavisolibacter, Opitutus, Desulf...   \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....  [Erysipelothrix, Phreatobacter, Geothrix, Opit...   \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...  [Staphylococcus, Thermincola, Acidisoma, Prevo...   \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)  [Thiobacillus, Thermincola, Prevotella, Mycoba...   \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate  [Staphylococcus, Acetobacterium, Prevotella, D...   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  [Erysipelothrix, Thermincola, Acidisoma, Geoth...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  [Brevibacterium, Mycobacterium, Oerskovia, Opi...   \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...  [Erysipelothrix, Thermincola, Prevotella, Acid...   \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl  [Aestuariimicrobium, Thermincola, Oxalobactera...   \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...  [Thiobacillus, Thermincola, Mycobacterium, Myc...   \n",
      "bifunctional enzyme ispd-ispf [                     [Phreatobacter, Porphyrobacter, Mycoplana, Tre...   \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...  [Thermincola, Desulfomicrobium, Oxalobacterace...   \n",
      "\n",
      "                                                                                functional_categories  \\\n",
      "protein_name                                                                                            \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                    iron/sulfur_redox; acid_production; electron t...   \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                iron/sulfur_redox; acid_production; electron t...   \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...  iron/sulfur_redox; acid_production; electron t...   \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....  iron/sulfur_redox; acid_production; electron t...   \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...  iron/sulfur_redox; acid_production; electron t...   \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)  iron/sulfur_redox; acid_production; electron t...   \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate  iron/sulfur_redox; acid_production; electron t...   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  iron/sulfur_redox; ocre; acid_production; elec...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  iron/sulfur_redox; acid_production; electron t...   \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...  iron/sulfur_redox; acid_production; electron t...   \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl  iron/sulfur_redox; acid_production; electron t...   \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...  iron/sulfur_redox; acid_production; electron t...   \n",
      "bifunctional enzyme ispd-ispf [                     iron/sulfur_redox; acid_production; electron t...   \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...  iron/sulfur_redox; acid_production; electron t...   \n",
      "\n",
      "                                                                                       niche_pathways  \\\n",
      "protein_name                                                                                            \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                    fatty acid biosynthesis; lipid biosynthesis pr...   \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                fatty acid biosynthesis; biotin ; lipid biosyn...   \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...  fatty acid biosynthesis; biotin ; lipid biosyn...   \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....                          nitrogen , nitrogen cycle   \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...                          nitrogen , nitrogen cycle   \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)                          nitrogen , nitrogen cycle   \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate                          nitrogen , nitrogen cycle   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  alanine, aspartate and glutamate ; cysteine an...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...                          nitrogen , nitrogen cycle   \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...                          nitrogen , nitrogen cycle   \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl  fatty acid biosynthesis; lipid biosynthesis pr...   \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...                          nitrogen , nitrogen cycle   \n",
      "bifunctional enzyme ispd-ispf [                                             nitrogen , nitrogen cycle   \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...                                           proteins   \n",
      "\n",
      "                                                                                        enzyme_class  \\\n",
      "protein_name                                                                                           \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                                Acting on the CH-CH group of donors.   \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                            Acting on the CH-OH group of donors.   \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...              Acting on the CH-CH group of donors.   \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....  Acting on other nitrogenous compounds as donors.   \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...  Acting on other nitrogenous compounds as donors.   \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)  Acting on other nitrogenous compounds as donors.   \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate  Acting on other nitrogenous compounds as donors.   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...                  Transferring nitrogenous groups.   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  Acting on other nitrogenous compounds as donors.   \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...  Acting on other nitrogenous compounds as donors.   \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl              Acting on the CH-CH group of donors.   \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...  Acting on other nitrogenous compounds as donors.   \n",
      "bifunctional enzyme ispd-ispf [                     Acting on other nitrogenous compounds as donors.   \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...         Acting on iron-sulfur proteins as donors.   \n",
      "\n",
      "                                                                                 corrosion_mechanisms  \\\n",
      "protein_name                                                                                            \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                    biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  carbon_metabolism; biofilm_formation; sulfur_m...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "bifunctional enzyme ispd-ispf [                     biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "\n",
      "                                                                                          explanation  \\\n",
      "protein_name                                                                                            \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                    Corrosion relevance (39.3) | Metal interaction...   \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                Corrosion relevance (39.9) | Metal interaction...   \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...  Corrosion relevance (39.9) | Metal interaction...   \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....  Corrosion relevance (39.5) | Metal interaction...   \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...  Corrosion relevance (39.5) | Metal interaction...   \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)  Corrosion relevance (39.5) | Metal interaction...   \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate  Corrosion relevance (39.5) | Metal interaction...   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  Corrosion relevance (39.0) | Metal interaction...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  Corrosion relevance (39.5) | Metal interaction...   \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...  Corrosion relevance (39.5) | Metal interaction...   \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl  Corrosion relevance (39.3) | Metal interaction...   \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...  Corrosion relevance (39.5) | Metal interaction...   \n",
      "bifunctional enzyme ispd-ispf [                     Corrosion relevance (39.5) | Metal interaction...   \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...  Corrosion relevance (40.2) | Metal interaction...   \n",
      "\n",
      "                                                                                                Sites  \n",
      "protein_name                                                                                           \n",
      "enoyl-[ reductase [ (ec 1.3.1.9)                    [site_16, site_29, site_14, site_32, site_13, ...  \n",
      "3-oxoacyl-[ reductase (ec 1.1.1.100)                [site_16, site_1, site_14, site_12, site_32, s...  \n",
      "enoyl-[ reductase (nadph, si-specific); acyl-ac...  [site_29, site_14, site_32, site_13, site_10, ...  \n",
      "glutathione hydrolase proenzyme (ec 2.3.2.2) 3....  [site_1, site_64, site_29, site_12, site_56, s...  \n",
      "gmp-synthase [ (ec 6.3.5.2) (gmp-synthetase) (g...  [site_14, site_32, site_47, site_8, site_44, s...  \n",
      "glutamine-dependent nad(+) synthetase (ec 6.3.5.1)  [site_29, site_14, site_10, site_44, site_8, s...  \n",
      "aspartate 1-decarboxylase (ec 4.1.1.11) (aspartate  [site_40, site_14, site_32, site_63, site_56, ...  \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  [site_56, site_8, site_44, site_47, site_65, s...  \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  [site_1, site_14, site_29, site_32, site_63, s...  \n",
      "dna ligase (ec 6.5.1.2) (polydeoxyribonucleotid...  [site_64, site_14, site_10, site_8, site_44, s...  \n",
      "enoyl-[ reductase (nadh); enoyl-[ reductase; enoyl  [site_20, site_14, site_56, site_31, site_11, ...  \n",
      "holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7...  [site_16, site_13, site_8, site_22, site_53, s...  \n",
      "bifunctional enzyme ispd-ispf [                                    [site_10, site_8, site_1, site_11]  \n",
      "ferredoxin---nadp+ reductase; ferredoxin-nicoti...                        [site_56, site_15, site_12]  \n"
     ]
    }
   ],
   "source": [
    "# First, establish the descriptors and categorical descriptors\n",
    "categorical_descriptors = ['protein_name', 'genera', 'functional_categories', 'niche_pathways', \n",
    "                         'enzyme_class', 'corrosion_mechanisms', 'explanation', 'Sites']\n",
    "numerical_descriptors = ['genera_count', 'combined_score']\n",
    "\n",
    "# 1. Create the protein_descriptors dataframe\n",
    "# Start with the columns we need\n",
    "protein_descriptors_raw = protein_hierarchy[categorical_descriptors + numerical_descriptors]\n",
    "\n",
    "# Define custom aggregation functions for different column types\n",
    "def agg_lists(x):\n",
    "    # If already a list, flatten and get unique items\n",
    "    if isinstance(x.iloc[0], list):\n",
    "        flattened = []\n",
    "        for item in x:\n",
    "            if isinstance(item, list):\n",
    "                flattened.extend(item)\n",
    "            else:\n",
    "                flattened.append(item)\n",
    "        # Convert items to strings to make them hashable, then back to list\n",
    "        return list(set([str(i) for i in flattened]))\n",
    "    # If not a list but we want a list of unique values\n",
    "    else:\n",
    "        return list(set([str(i) for i in x]))\n",
    "\n",
    "def agg_first(x):\n",
    "    return x.iloc[0]\n",
    "\n",
    "# Create aggregation dictionary\n",
    "agg_dict = {\n",
    "    'combined_score': 'mean',\n",
    "    'genera_count': 'sum' \n",
    "}\n",
    "\n",
    "# Specify aggregation method for each descriptor column\n",
    "for col in categorical_descriptors:\n",
    "    if col != 'protein_name':  # Skip the groupby column\n",
    "        if col in ['genera', 'Sites']:  # Columns that should be lists of unique values\n",
    "            agg_dict[col] = agg_lists\n",
    "        else:  # Columns where we just want the first value\n",
    "            agg_dict[col] = agg_first\n",
    "\n",
    "# Group by protein_name and aggregate\n",
    "protein_descriptors = protein_descriptors_raw.groupby('protein_name').agg(agg_dict)\n",
    "protein_descriptors = protein_descriptors.sort_values(by='genera_count', ascending=False).head(100)\n",
    "\n",
    "print(protein_descriptors.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb01d9",
   "metadata": {},
   "source": [
    "# Integration with Data to equilibrate Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a4bdf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get all sites from classified_results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m all_classified_sites = \u001b[43mresults_dict\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mclassified_results\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mSites\u001b[39m\u001b[33m'\u001b[39m].unique()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal sites in classified_results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_classified_sites)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Get sites from balanced_markers\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'results_dict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all sites from classified_results\n",
    "all_classified_sites = results_dict['classified_results']['Sites'].unique()\n",
    "print(f\"Total sites in classified_results: {len(all_classified_sites)}\")\n",
    "\n",
    "# Get sites from balanced_markers\n",
    "balanced_sites = results_dict['balanced_markers']['Sites'].unique()\n",
    "print(f\"Sites in balanced_markers: {len(balanced_sites)}\")\n",
    "\n",
    "# Find missing sites\n",
    "missing_sites = set(all_classified_sites) - set(balanced_sites)\n",
    "print(f\"Missing sites: {len(missing_sites)}\")\n",
    "\n",
    "# For each missing site, get its data from classified_results\n",
    "missing_data = results_dict['classified_results'][\n",
    "    results_dict['classified_results']['Sites'].isin(missing_sites)\n",
    "]\n",
    "\n",
    "# You can either:\n",
    "# 1. Keep this as a separate dataset for analysis\n",
    "results_dict['missing_sites_data'] = missing_data\n",
    "\n",
    "# 2. Or combine with balanced_markers for a complete dataset\n",
    "complete_dataset = pd.concat([\n",
    "    results_dict['balanced_markers'], \n",
    "    missing_data\n",
    "], ignore_index=True)\n",
    "results_dict['complete_dataset'] = complete_dataset\n",
    "\n",
    "# Check if all sites are now accounted for\n",
    "all_sites_in_complete = results_dict['complete_dataset']['Sites'].unique()\n",
    "print(f\"Sites in complete dataset: {len(all_sites_in_complete)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the protein_nn dataframe\n",
    "protein_nn_columns = ['Sites', 'Category', 'protein_name', 'norm_abund_contri',\n",
    "                     'fold_change_2vs1', 'log2fc_2vs1', 'fold_change_3vs2',\n",
    "                     'log2fc_3vs2', 'fold_change_3vs1', 'log2fc_3vs1',\n",
    "                     'specificity', 'prevalence', 'max_abs_log2fc', 'combined_score']\n",
    "\n",
    "protein_nn_raw = protein_hierarchy[protein_nn_columns].head(100).copy()\n",
    "\n",
    "# Since we need Sites as the index and protein_names as columns, with norm_abund_contri as values, we'll pivot the dataframe\n",
    "protein_nn_pivoted = protein_nn_raw.pivot_table(\n",
    "    index='Sites',\n",
    "    columns='protein_name',\n",
    "    values='norm_abund_contri',\n",
    "    aggfunc='mean'  \n",
    ")\n",
    "\n",
    "# preserving category\n",
    "site_categories = protein_nn_raw[['Sites', 'Category']].drop_duplicates().set_index('Sites')\n",
    "\n",
    "# Merge the Category back into the pivoted dataframe\n",
    "protein_nn = protein_nn_pivoted.copy()\n",
    "protein_nn = protein_nn.join(site_categories)\n",
    "\n",
    "# Move Category to the beginning of the dataframe\n",
    "category_col = protein_nn.pop('Category')\n",
    "protein_nn.insert(0, 'Category', category_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06345b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_hierarchy[\"Sites\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068db7e",
   "metadata": {},
   "source": [
    "# 4. Novel Candidates\n",
    "During the statistical feature analysis in Notebook 3, several bacterial genera were identified that showed strong correlations with the high-risk corrosion failure category. This led to hypothesize the potential of  of this microorganisms to be associated with corrosion processes and which were not previously documented.\n",
    "In Notebook 4, we conducted a comprehensive literature review using academic databases to investigate the bacterial genera. The findings confirmed that these microorganisms have no prior documentation in scientific literature linking them to corrosion-related processes.\n",
    "Now, we aim to deploy the analyze_protein_hierarchy function to examine whether these bacteria express proteins that are known to induce or accelerate corrosion. This analysis will help determine if these genera possess the molecular machinery to contribute to corrosion despite their absence from corrosion-related literature, potentially identifying novel microbial contributors to corrosion processes that have been overlooked in previous research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5580/2573382650.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  protein_df['pathway_cluster'] = clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>genera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enoyl-[ reductase [ (ec 1.3.1.9)</td>\n",
       "      <td>[Mycoplana]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d-aspartate ligase (ec 6.3.1.12)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tagatose-bisphosphate aldolase; d-tagatose-1,6...</td>\n",
       "      <td>[Bulleidia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thiosulfate-dehydrogenase (quinone); thiosulfa...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cholesterol oxidase (ec 1.1.3.6) 5.3.3.1) (cho...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chloramphenicol acetyltransferase (ec 2.3.1.28)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>endo-alpha-n-acetylgalactosaminidase (ec 3.2.1...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2,3-dihydro-2,3-dihydroxybenzoate-dehydrogenas...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2,3-dihydroxybenzoate-amp ligase (ec 2.7.7.58)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>selenide, water dikinase; selenophosphate-synt...</td>\n",
       "      <td>[Oxalobacteraceae_unclassified]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        protein_name  \\\n",
       "0                   enoyl-[ reductase [ (ec 1.3.1.9)   \n",
       "1                   d-aspartate ligase (ec 6.3.1.12)   \n",
       "2  tagatose-bisphosphate aldolase; d-tagatose-1,6...   \n",
       "3  thiosulfate-dehydrogenase (quinone); thiosulfa...   \n",
       "4  cholesterol oxidase (ec 1.1.3.6) 5.3.3.1) (cho...   \n",
       "5    chloramphenicol acetyltransferase (ec 2.3.1.28)   \n",
       "6  endo-alpha-n-acetylgalactosaminidase (ec 3.2.1...   \n",
       "7  2,3-dihydro-2,3-dihydroxybenzoate-dehydrogenas...   \n",
       "8     2,3-dihydroxybenzoate-amp ligase (ec 2.7.7.58)   \n",
       "9  selenide, water dikinase; selenophosphate-synt...   \n",
       "\n",
       "                            genera  \n",
       "0                      [Mycoplana]  \n",
       "1                      [Oerskovia]  \n",
       "2                      [Bulleidia]  \n",
       "3                      [Oerskovia]  \n",
       "4                      [Oerskovia]  \n",
       "5                      [Oerskovia]  \n",
       "6                      [Oerskovia]  \n",
       "7                      [Oerskovia]  \n",
       "8                      [Oerskovia]  \n",
       "9  [Oxalobacteraceae_unclassified]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary of genera identified as nobel on Notebook 4.\n",
    "new_genera= ['Oxalobacteraceae_unclassified', 'Oxobacter', 'Mycoplana', 'Bulleidia',  'Oerskovia']\n",
    "new_genera_df = balanced_markers[balanced_markers[\"Genus\"].isin(new_genera)]\n",
    "protein_candidates_markers = analyze_protein_hierarchy_rf(new_genera_df, n_estimators=100, n_top_proteins=5, random_state=42)\n",
    "protein_candidates_markers[[\"protein_name\", \"genera\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c2eeb",
   "metadata": {},
   "source": [
    "# 5. File Integration of Microbiological Data and Physicochemical Data\n",
    "df_physicochemical comprises the selected features phychem_features and the whole set of parameters if necesary for plotting purposes.\n",
    "The df_micro is the df of protein-genus features selected from the notebook 7_visual_proteins_ipnyb\n",
    "micro_usuals is a dictionary with the list of proven bacteria influencing corrosion and could serve as label for plotting purposes\n",
    "micro_markers is the dictionary with the list of bacteria belonging to the df_micro dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ac79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_physicochemical = Path(\"/home/beatriz/MIC/1_Physicochemical/Data/\")\n",
    "physichem_path = data_physicochemical /\"Physicochemical.xlsx\"\n",
    "\n",
    "all_physicochemical = pd.read_excel(physichem_path, sheet_name='all_physicochemical', engine ='openpyxl')\n",
    "metadata = pd.read_excel(physichem_path, sheet_name='Metadata', engine ='openpyxl')\n",
    "\n",
    "\n",
    "physichem_features = ['Temperature', 'Type', 'EC_M', 'O2_Eh',\n",
    "                     'Ox_Fe_Zn', 'Cl_SO4_NO3', 'Na_K','pH_HPO4',\n",
    "                       'Ca_HCO3_Mg', 'Cu_Al_Mn', 'Ni_Cr_Mo']\n",
    "physichem_df = all_physicochemical[physichem_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dafa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'protein_markers' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m micro_df= \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprotein_markers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m all_physichem = pd.read_excel(combined_path, sheet_name=\u001b[33m'\u001b[39m\u001b[33mall_physicochemical\u001b[39m\u001b[33m'\u001b[39m, engine =\u001b[33m'\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m genus_site_df = pd.read_excel(combined_path, sheet_name=\u001b[33m'\u001b[39m\u001b[33mgenus_to_sites\u001b[39m\u001b[33m'\u001b[39m, engine =\u001b[33m'\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MIC/3_combined/.venv/lib/python3.12/site-packages/pandas/io/excel/_base.py:508\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     data = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    534\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MIC/3_combined/.venv/lib/python3.12/site-packages/pandas/io/excel/_base.py:1616\u001b[39m, in \u001b[36mExcelFile.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\n\u001b[32m   1577\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1578\u001b[39m     sheet_name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m     **kwds,\n\u001b[32m   1597\u001b[39m ) -> DataFrame | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[32m   1598\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1599\u001b[39m \u001b[33;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[32m   1600\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1614\u001b[39m \u001b[33;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   1615\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MIC/3_combined/.venv/lib/python3.12/site-packages/pandas/io/excel/_base.py:773\u001b[39m, in \u001b[36mBaseExcelReader.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m    770\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masheetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asheetname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     sheet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43masheetname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume an integer if not a string\u001b[39;00m\n\u001b[32m    775\u001b[39m     sheet = \u001b[38;5;28mself\u001b[39m.get_sheet_by_index(asheetname)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MIC/3_combined/.venv/lib/python3.12/site-packages/pandas/io/excel/_openpyxl.py:582\u001b[39m, in \u001b[36mOpenpyxlReader.get_sheet_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_if_bad_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.book[name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MIC/3_combined/.venv/lib/python3.12/site-packages/pandas/io/excel/_base.py:624\u001b[39m, in \u001b[36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_if_bad_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sheet_names:\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWorksheet named \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Worksheet named 'protein_markers' not found"
     ]
    }
   ],
   "source": [
    "micro_df= pd.read_excel(combined_path, sheet_name='protein_markers',  engine ='openpyxl')\n",
    "all_physichem = pd.read_excel(combined_path, sheet_name='all_physicochemical', engine ='openpyxl')\n",
    "genus_site_df = pd.read_excel(combined_path, sheet_name='genus_to_sites', engine ='openpyxl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5418bc3",
   "metadata": {},
   "source": [
    "Validation\n",
    "As a first approximation I will take the first 20 with best score, but I will have to iterate through the list and check if these proteins are really relevant to corrosion states or are also found on the other part of the community the other 800 bacteria and if so what is the numerical diffence, if as I think these are universal proteins and belong infact also to the other part of the community, then we have to discard them and found the ones that really make a difference on the failed systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc09ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33351487",
   "metadata": {},
   "source": [
    "# 5. Proteins Associated with Corrosion from the Literature\n",
    "In this section a querry to the group balanced markers is done with the aim to find the following proteins which have been associated with corrosion in the literature\n",
    "all_physiche balanced_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a024a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-dehydrogenase: Pseudarthrobacter\n",
      "enoyl-[ reductase (nadph, si-specific); acyl-acp-dehydrogenase: Gallionella\n",
      "isocitrate-dehydrogenase [ (ec 1.1.1.42): Gallionella\n",
      "2-iminoacetate-synthase (ec 4.1.99.19) ([ hydrogenase: Clostridium\n",
      "(r,r)-butanediol-dehydrogenase; butyleneglycol-dehydrogenase;: Paracoccus\n",
      "saccharopine-dehydrogenase (nad+, l-lysine-forming: Desulfobulbus\n",
      "(s,s)-butanediol-dehydrogenase; l-butanediol-dehydrogenase;: Porphyrobacter\n",
      "meso-butanediol-dehydrogenase-(s,s)-butanediol-dehydrogenase: Variovorax\n",
      "cytochrome-c3 hydrogenase; h2:ferricytochrome c3 oxido: Desulfobacterium\n",
      "glycerol-3-phosphate-dehydrogenase (ec 1.1.5.3): Phreatobacter\n",
      "nadph-dehydrogenase (ec 1.6.99.1): Bacillus\n",
      "ferredoxin hydrogenase; h2 oxidizing hydrogenase; h2: Hydrogenophaga\n",
      "2-oxoisovalerate-dehydrogenase subunit alpha (ec 1: Blastomonas\n",
      "polyvinylalcohol-dehydrogenase (ec 1.1.2.6): Bradyrhizobium\n",
      "decarboxylase-oxoglutarate-dehydrogenase thiamine pyrophosphate: Corynebacterium\n",
      "thiosulfate-dehydrogenase (quinone); thiosulfate:quinone: Oerskovia\n",
      "glutamate-dehydrogenase-leucine-dehydrogenase (ec 1: Porphyrobacter\n",
      "l-carnitine-dehydrogenase (cdh) (l-cdh) (ec 1.1.1.108: Halomonas\n",
      "3(or 17)beta-hydroxysteroid-dehydrogenase; beta-hydroxy: Ralstonia\n",
      "hydrogen-dehydrogenase (nadp+); nadp+-linked hydrogenase;: Wchb1-05\n",
      "r,r-butanediol-dehydrogenase-diacetyl-reductase (ec: Neisseria\n",
      "butanediol-dehydrogenase (ec 1.1.1.4) (zinc-binding: Neisseria\n",
      "serine 3-dehydrogenase (nadp+); serine 3-dehydrogenase: Sphingopyxis\n",
      "3-hydroxy acid-dehydrogenase; ydfg (gene name); ymr226c: Enhydrobacter\n",
      "isocitrate-dehydrogenase (ec 1.1.1.41): Pseudoalteromonas\n",
      "sorbitol-dehydrogenase (ec 1.1.99.21): Halomonas\n",
      "3-alpha-(or 20-beta)-hydroxysteroid-dehydrogenase: Sphingobium\n",
      "hydroxybenzaldehyde-dehydrogenase (ec 1.2.1.28): Ralstonia\n",
      "udp-n-acetyl-d-glucosamine 6-dehydrogenase (ec 1.1: Syntrophus\n",
      "sulfite-dehydrogenase (ec 1.8.2.1): Dechloromonas\n",
      "acetaldehyde-dehydrogenase (acetylating); aldehyde: Psb-m-3\n",
      "2,3-dihydro-2,3-dihydroxybenzoate-dehydrogenase (ec: Oerskovia\n",
      "protoporphyrinogen ix-dehydrogenase [ (ec 1.3.5.3): Shewanella\n",
      "benzaldehyde-dehydrogenase (nad) (ec 1.2.1.28): Pseudoxanthomonas\n",
      "uronate-dehydrogenase; uronate:nad-oxido-reductase;: Hydrogenophaga\n",
      "sorbitol-6-phosphate 2-dehydrogenase (ec 1.1.1.140: Enterococcus\n",
      "3,4-dehydroadipyl-coa semialdehyde-dehydrogenase (nadp+: Beta_proteobacterium\n",
      "glutamate-dehydrogenase [; glutamic-dehydrogenase;: Dechloromonas\n",
      "d-arabinitol 4-dehydrogenase; d-arabitol-dehydrogenase;: Hydrogenophaga\n",
      "erythronate-4-phosphate-dehydrogenase (ec 1.1.1.290: Prevotella\n",
      "formaldehyde-dehydrogenase mscr, nad-mycothiol-dependent: Brevibacterium\n",
      "hydrogenase (acceptor) (ec 1.12.99.6): Hydrogenophaga\n",
      "cytochrome-c3 hydrogenase; h2:ferricytochrome c3 oxido: Desulfobacterium\n",
      "cytochrome c-552 (ec 1.7.2.2) (ammonia-forming c nitrite: Shewanella\n",
      "glycosyltransferase (ec 2.4.1.57): Corynebacterium\n",
      "glycosyltransferase (ec 2.4.1.208): Erysipelothrix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define search terms for each protein group - using partial matches rather than just startswith\n",
    "protein_search_terms = {\n",
    "    'hydrogenase': ['hydrogenase', '[nife]', '[fefe]', 'fe-only hydrogenase', 'ni-fe hydrogenase'],\n",
    "    'cytochrome': ['cytochrome c', 'c-type cytochrome', 'cytc'],\n",
    "    'sulfite_reductase': ['dissimilatory sulfite reductase', 'dsrab', 'dsr', 'sulfite reductase'],\n",
    "    'metal_resistance': ['cobalt-zinc-cadmium resistance', 'czca', 'metal efflux', 'metal resistance'],\n",
    "    'quorum_sensing': ['ahl synthase', 'luxi', 'luxr', 'autoinducer synthase', 'quorum sensing'],\n",
    "    'eps_production': ['glycosyltransferase', 'eps synthase', 'exopolysaccharide']\n",
    "}\n",
    "\n",
    "# Function to check if protein name contains any of the search terms\n",
    "def matches_protein_group(protein_name, search_terms):\n",
    "    protein_name_lower = protein_name.lower()\n",
    "    return any(term.lower() in protein_name_lower for term in search_terms)\n",
    "\n",
    "# Create dictionaries to store results\n",
    "found_proteins = {category: [] for category in protein_search_terms}\n",
    "\n",
    "# Search for proteins in each category\n",
    "for category, terms in protein_search_terms.items():\n",
    "    # Create condition that checks if protein_name contains any of the search terms\n",
    "    match_condition = balanced_markers[\"protein_name\"].apply(\n",
    "        lambda x: matches_protein_group(x, terms)\n",
    "    )\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    matched_proteins = balanced_markers[match_condition]\n",
    "    \n",
    "    # Store results\n",
    "    found_proteins[category] = matched_proteins\n",
    "    for protein_name in matched_proteins[\"protein_name\"].unique():\n",
    "        # Get the genera for this protein\n",
    "        protein_rows = matched_proteins[matched_proteins['protein_name'] == protein_name]\n",
    "        genera_value = protein_rows['Genus'].iloc[0]\n",
    "        \n",
    "        # Check if the genera is already a list or a string representation of a list\n",
    "        if isinstance(genera_value, list):\n",
    "            genera_list = genera_value\n",
    "        else:\n",
    "            # Try to evaluate as a Python list if it's a string representation\n",
    "            import ast\n",
    "            try:\n",
    "                genera_list = ast.literal_eval(genera_value)\n",
    "            except:\n",
    "                # If it's just a single string, wrap it in a list\n",
    "                genera_list = [genera_value]\n",
    "        \n",
    "        # Print the protein name and joined genera\n",
    "        print(f\"{protein_name}: {', '.join(genera_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb63da",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (3515341291.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mwith pd.ExcelWriter(combined_path, mode=\"a\", engine='openpyxl') , if_sheet_exists=\"replace\") as writer:\u001b[39m\n                                                                                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(combined_path, mode=\"a\", engine='openpyxl') , if_sheet_exists=\"replace\" as writer:\n",
    "    protein_markers.to_excel(writer, sheet_name= \"protein_markers\", index=True, freeze_panes=(1,0))\n",
    "    all_physicochemical.to_excel(writer, sheet_name= \"all_physicochemical\", index=True, freeze_panes=(1,0))\n",
    "    metadata.to_excel(writer, sheet_name= \"Metadata\", index=True, freeze_panes=(1,0))\n",
    "    protein_candidates.to_excel(writer, sheet_name= \"candidates\", index=True, freeze_panes=(1,0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_Combined Environment",
   "language": "python",
   "name": "combined_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
