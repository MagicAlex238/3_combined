{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f36d6a4",
   "metadata": {},
   "source": [
    "# Clustering Proteins and Data Integration\n",
    "# 1. Introduction\n",
    "\n",
    "# 2. Preparing and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645b30b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install kneed'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install kneed'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a547a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_4312/896945112.py\", line 19, in <module>\n",
      "    import torch\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Data processing and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Standard library imports\n",
    "import ast\n",
    "import subprocess\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import re\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.metrics import silhouette_score\n",
    "from kneed import KneeLocator\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import to_rgba, LinearSegmentedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import kaleido\n",
    "\n",
    "# Machine learning and statistical analysis\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import umap\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import spearmanr, kruskal, mannwhitneyu\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import shap\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "# Utility libraries\n",
    "import gzip\n",
    "import random\n",
    "from natsort import natsorted\n",
    "from typing import Dict, List, Tuple, Set, Optional\n",
    "import gc\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "\n",
    "# Dash\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, callback, State\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Own Scoring system\n",
    "import corrosion_scoring as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca72e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local (VSCode) environment\n"
     ]
    }
   ],
   "source": [
    "# Determine the environment\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Running in Google Colab environment\")\n",
    "    # for colab\n",
    "    base_dir = Path(\"/content/drive/MyDrive/MIC\")\n",
    "    abundance_excel = base_dir / \"data_picrust/merged_to_sequence.xlsx\"\n",
    "    output_large = base_dir / \"output_large\"\n",
    "    output_base = base_dir\n",
    "    market_dir = base_dir / \"output_large\" \n",
    "    #Directory to keep some Results\n",
    "    large_dir = base_dir / \"2_Micro/data_visual\"\n",
    "    large_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "elif Path(\"/kaggle\").exists():\n",
    "    print(\"Running in Kaggle environment\")\n",
    "    # For Kaggle work# Input datasets (read-only in Kaggle) \n",
    "    base_dir = Path(\"/kaggle/input/\")  \n",
    "    abundance_excel = base_dir / \"new-picrust/merged_to_sequence.xlsx\" \n",
    "    #Input physicochemical variables\n",
    "    data_physicochemical = base_dir / \"physicochemical-parameters/Physicochemical.xlsx\"\n",
    "    combined_input = base_dir  / \"combined_markers.xlsx\"\n",
    "    #===============================================\n",
    "    #Directory to keep  Results\n",
    "    output_base = Path(\"/kaggle/working/\")\n",
    "    shared_dir = output_base/\"Visualisations\"\n",
    "    shared_dir.mkdir(parents=True, exist_ok=True)\n",
    "    combined_path = output_base / \"combined_markers.xlsx\"\n",
    "      \n",
    "else:\n",
    "    print(\"Running in local (VSCode) environment\")\n",
    "    base_dir = Path(\"data\")\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Base Paths for local environment\n",
    "    abundance_excel = base_dir / \"merged_to_sequence.xlsx\"\n",
    "    #Input physicochemical variables8ikk                           ´\n",
    "    data_physicochemical = Path(\"/home/beatriz/MIC/1_Physicochemical/Data/Physicochemical.xlsx\")\n",
    "    #================================================\n",
    "    # This files are too large for github and are store on Kaggle for educational purposes\n",
    "    output_large = Path(\"/home/beatriz/MIC/output_large\")\n",
    "    output_base = base_dir \n",
    "    #Directory to keep some Results\n",
    "    shared_dir= Path(\"/home/beatriz/SharedFolder/Visualisations/\")\n",
    "    combined_path = base_dir / \"combined_markers.xlsx\"\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc808b5",
   "metadata": {},
   "source": [
    "### Importing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf81ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physicochemical data data from notebook 8 repo 1_Physicochemical\n",
    "all_physichem = pd.read_excel(data_physicochemical, sheet_name='all_physicochemical', engine ='openpyxl')\n",
    "# Microbiological Data from notebook 6 repo 2_Micro.\n",
    "df_proteins= pd.read_excel(combined_path, sheet_name='df_proteins',  engine ='openpyxl')\n",
    "#mapping of genera to site from the original df for validation\n",
    "genus_site_df = pd.read_excel(combined_path, sheet_name='genus_to_sites', engine ='openpyxl')\n",
    "# All markers after pattern, integration, classification, increasing, and balance functions\n",
    "balanced_markers= pd.read_excel(combined_path, sheet_name='balanced_markers', engine ='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040495c",
   "metadata": {},
   "source": [
    "# 3 Functional Category groups and Random Forest importance\n",
    "Using functional Category groups and Random Forest importance to select top markers.This rf integrates the functional categories from the cs package, uses Random Forest to identify the most important features for predicting corrosion risk and groups them by functional category to understand which biological processes are most informative, but also an additional step will communicate the niche specific processes. Then uses SHAP values for more interpretable feature importance. At end a selected balanced set of features representing different functional categories is chosen mapping the features back to specific proteins for biological interpretation.\n",
    "The chosen column to be associating the data or to serve as integration factor was the \"functional_categories\" or \"fc_present\" both of which presented similar entries and it was finally decided to cluster instead according to the \"niche_specific_pathways\" the reason is because the granularity it contains more differentiation between proteins already very similar all being at this point mostly on category 3. The functional_category, corrosion_mechanisms, enzyme_class and explanation columns are also brough forward to have the richness of the information. Additionally Columns Sites, Categories, combined_score, protein_name and genus would be also brought. \n",
    "\n",
    "The results from the function analyze_protein_hierachy gives a comprehensive dataframe. This is a single flattened DataFrame combining both descriptive and explanatory metadata and numerical attributes those are:  \n",
    "* Fields that support interpretation and discussion of each protein:  \n",
    " ['Sites', 'protein_name', 'genera_count', 'genera', 'functional_categories', 'niche_pathways', 'enzyme_class', 'corrosion_mechanisms',  'explanation', 'combined_score']\n",
    "* Fields that with values that feed a supervised neural network in Notebook 2:  \n",
    "['Sites','Category','protein_name', norm_abund_contri', 'fold_change_2vs1', 'log2fc_2vs1', 'fold_change_3vs2', 'log2fc_3vs2', 'fold_change_3vs1', 'log2fc_3vs1',  'specificity', 'prevalence', 'max_abs_log2fc', 'combined_score'] \n",
    "The idea of the operation is to mantain the original relationships so hat each row represents one unique (protein-genus-site) observation preserving the original abundance granularity from the PICRUSTt2  OTU→EC→protein mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f092d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_protein_hierarchy_rf(protein_df, n_estimators=100, n_top_proteins=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Analyzes protein hierarchy using Random Forest for feature importance,\n",
    "    performs hierarchical clustering on niche-specific pathways,\n",
    "    and returns a comprehensive DataFrame with both descriptive and numerical attributes.\n",
    "    \n",
    "    Parameters: protein_df : DataFrame Input DataFrame containing protein data with all required columns\n",
    "    n_estimators : int, default=100   Number of trees in the Random Forest\n",
    "    n_top_proteins : int, default=50  Number of top proteins to select based on importance\n",
    "    random_state : int, default=42  Random seed for reproducibility\n",
    "    \n",
    "    Returns:  DataFrame  Comprehensive DataFrame with selected proteins and all required attributes\n",
    "    \"\"\"\n",
    "    # Step 1: Prepare data for Random Forest: features for importance ranking (numerical columns)\n",
    "    numerical_features = ['fold_change_2vs1', 'log2fc_2vs1', 'fold_change_3vs2', 'log2fc_3vs2', 'fold_change_3vs1', 'log2fc_3vs1', \n",
    "                         'specificity', 'prevalence', 'max_abs_log2fc', 'combined_score']\n",
    "    \n",
    "    # Create dummy target for feature importance using 'Category' as a proxy target\n",
    "    X = protein_df[numerical_features].fillna(0)\n",
    "    y = protein_df['Category']\n",
    "    \n",
    "    # Step 2: Train Random Forest for feature importance    \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Step 3: Calculate SHAP values for feature importance interpretation\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # Average across samples\n",
    "    sample_averaged = np.mean(shap_values, axis=0)  # Shape: (10, 3)\n",
    "\n",
    "    # Take absolute values\n",
    "    absolute_values = np.abs(sample_averaged)  # Still (10, 3)\n",
    "\n",
    "    # Average across classes to get a single importance score per feature\n",
    "    shap_importance = np.mean(absolute_values, axis=1)  # Final shape: (10,)\n",
    "\n",
    "    # Create feature importance DataFrame\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': numerical_features,\n",
    "        'importance': rf.feature_importances_,\n",
    "        'shap_importance': shap_importance\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('shap_importance', ascending=False)\n",
    "    #======================================================\n",
    "    # Step 4: Hierarchical clustering based on niche-specific pathways\n",
    "    # First, create a distance matrix from the pathway information: Convert niche-specific pathways to a TF-IDF matrix\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # Handle missing values\n",
    "    pathway_texts = protein_df['niche_specific_pathways'].fillna('')\n",
    "    pathway_matrix = tfidf.fit_transform(pathway_texts)\n",
    "    \n",
    "    # Compute hierarchical clustering\n",
    "    Z = linkage(pathway_matrix.toarray(), method='ward')\n",
    "    \n",
    "    # Determine optimal number of clusters compute different clustering solutions\n",
    "    max_clusters = min(20, len(protein_df))\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for n_clusters in range(2, max_clusters + 1):\n",
    "        clusters = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "        if len(np.unique(clusters)) <= 1:\n",
    "            silhouette_scores.append(0)\n",
    "        else:\n",
    "            silhouette_scores.append(silhouette_score(pathway_matrix.toarray(), clusters))\n",
    "    \n",
    "    # Find optimal number of clusters using knee point detection\n",
    "    kl = KneeLocator(range(2, max_clusters + 1), silhouette_scores, \n",
    "                    curve='concave', direction='increasing')\n",
    "    optimal_clusters = kl.elbow if kl.elbow else 5  # Default to 5 if no clear elbow\n",
    "    \n",
    "    # Assign clusters\n",
    "    clusters = fcluster(Z, optimal_clusters, criterion='maxclust')\n",
    "    protein_df['pathway_cluster'] = clusters\n",
    "    \n",
    "    # Step 5: Evaluate protein importance within functional categories\n",
    "    # Add importance to original dataframe\n",
    "    protein_importance = {}\n",
    "    for idx, row in protein_df.iterrows():\n",
    "        protein_name = row['protein_name']\n",
    "        protein_importance[protein_name] = protein_importance.get(protein_name, 0)\n",
    "        \n",
    "        # Calculate importance based on the SHAP values of numerical features\n",
    "        for i, feature in enumerate(numerical_features):\n",
    "            if not pd.isna(row[feature]):\n",
    "                feature_weight = feature_importance.loc[\n",
    "                    feature_importance['feature'] == feature, 'shap_importance'].values[0]\n",
    "                protein_importance[protein_name] += row[feature] * feature_weight\n",
    "    \n",
    "    # Create a DataFrame with protein importance\n",
    "    protein_importance_df = pd.DataFrame({\n",
    "        'protein_name': list(protein_importance.keys()),\n",
    "        'importance_score': list(protein_importance.values())\n",
    "    }).sort_values('importance_score', ascending=False)\n",
    "    \n",
    "    # Step 6: Select a balanced set of top proteins. First, group by functional categories\n",
    "    fc_grouped = protein_df.groupby('functional_categories_present')\n",
    "    \n",
    "    # Select top proteins from each functional category\n",
    "    selected_proteins = []\n",
    "    for fc, group in fc_grouped:\n",
    "        # Get proteins in this functional category\n",
    "        fc_proteins = group['protein_name'].unique()\n",
    "        \n",
    "        # Get importance scores for these proteins\n",
    "        fc_importance = protein_importance_df[\n",
    "            protein_importance_df['protein_name'].isin(fc_proteins)\n",
    "        ]\n",
    "        \n",
    "        # Select top proteins from this category (proportional to category size)\n",
    "        n_select = max(1, int(len(fc_proteins) * n_top_proteins / len(protein_df['protein_name'].unique())))\n",
    "        top_fc_proteins = fc_importance.head(n_select)['protein_name'].tolist()\n",
    "        selected_proteins.extend(top_fc_proteins)\n",
    "    \n",
    "    # Step 7: Create and return the comprehensive DataFrame and filter to selected proteins\n",
    "    comprehensive_df = protein_df[protein_df['protein_name'].isin(selected_proteins)]\n",
    "    \n",
    "    # Add group count information\n",
    "    genera_counts = comprehensive_df.groupby('protein_name')['Genus'].nunique().reset_index()\n",
    "    genera_counts.columns = ['protein_name', 'genera_count']\n",
    "    \n",
    "    genera_lists = comprehensive_df.groupby('protein_name')['Genus'].apply(list).reset_index()\n",
    "    genera_lists.columns = ['protein_name', 'genera']\n",
    "    \n",
    "    # Merge with comprehensive_df\n",
    "    comprehensive_df = comprehensive_df.merge(genera_counts, on='protein_name', how='left')\n",
    "    comprehensive_df = comprehensive_df.merge(genera_lists, on='protein_name', how='left')\n",
    "    \n",
    "    # Add importance scores\n",
    "    comprehensive_df = comprehensive_df.merge(\n",
    "        protein_importance_df[['protein_name', 'importance_score']], \n",
    "        on='protein_name', how='left'\n",
    "    )\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    comprehensive_df = comprehensive_df.rename(columns={\n",
    "        'niche_specific_pathways': 'niche_pathways'\n",
    "    })\n",
    "    \n",
    "    # Ensure all required columns are present\n",
    "    descriptive_fields = ['Sites', 'protein_name', 'genera_count', 'genera', \n",
    "                         'functional_categories', 'niche_pathways', 'enzyme_class', \n",
    "                         'corrosion_mechanisms', 'explanation', 'combined_score']\n",
    "    \n",
    "    numerical_fields = ['Sites', 'Category', 'protein_name', 'norm_abund_contri',\n",
    "                       'fold_change_2vs1', 'log2fc_2vs1', 'fold_change_3vs2', \n",
    "                       'log2fc_3vs2', 'fold_change_3vs1', 'log2fc_3vs1', \n",
    "                       'specificity', 'prevalence', 'max_abs_log2fc', 'combined_score']\n",
    "    \n",
    "    # Select columns for final output\n",
    "    all_required_fields = list(set(descriptive_fields + numerical_fields))\n",
    "    output_columns = [col for col in all_required_fields if col in comprehensive_df.columns]\n",
    "    \n",
    "    # Add importance score and cluster information\n",
    "    output_columns += ['importance_score', 'pathway_cluster']\n",
    "    \n",
    "    return comprehensive_df[output_columns]\n",
    "\n",
    "protein_hierarchy = analyze_protein_hierarchy_rf(df_proteins, n_estimators=100, n_top_proteins=50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f54d1b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    combined_score  \\\n",
      "protein_name                                                         \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...       53.040891   \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...       52.022400   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...       50.315920   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...       50.226428   \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...       49.663520   \n",
      "\n",
      "                                                    genera_count  \\\n",
      "protein_name                                                       \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...            16   \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...             1   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...            36   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...             9   \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...            81   \n",
      "\n",
      "                                                                                               genera  \\\n",
      "protein_name                                                                                            \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...  [Acidisoma, Pseudorhodoferax, Simplicispira, M...   \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...                                [Pseudarthrobacter]   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  [Pseudorhodoferax, Gallionella, Anoxybacillus,...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  [Pseudorhodoferax, Pseudarthrobacter, Acidovorax]   \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...  [Pseudorhodoferax, Azospira, Acidisoma, Anoxyb...   \n",
      "\n",
      "                                                                                functional_categories  \\\n",
      "protein_name                                                                                            \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...  iron/sulfur_redox; acid_production; electron t...   \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...  iron/sulfur_redox; acid_production; electron t...   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  iron/sulfur_redox; ocre; acid_production; elec...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  iron/sulfur_redox; acid_production; electron t...   \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...  iron/sulfur_redox; acid_production; electron t...   \n",
      "\n",
      "                                                                                       niche_pathways  \\\n",
      "protein_name                                                                                            \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...  fatty acid degradation; toluene degradation; b...   \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...                                          butanoate   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  alanine, aspartate and glutamate ; cysteine an...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...                          nitrogen , nitrogen cycle   \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...                          nitrogen , nitrogen cycle   \n",
      "\n",
      "                                                                                        enzyme_class  \\\n",
      "protein_name                                                                                           \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...         Acting on iron-sulfur proteins as donors.   \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...              Acting on the CH-OH group of donors.   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...                  Transferring nitrogenous groups.   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  Acting on other nitrogenous compounds as donors.   \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...  Acting on other nitrogenous compounds as donors.   \n",
      "\n",
      "                                                                                 corrosion_mechanisms  \\\n",
      "protein_name                                                                                            \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  carbon_metabolism; biofilm_formation; sulfur_m...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...  biofilm_formation; sulfur_metabolism; o2_consu...   \n",
      "\n",
      "                                                                                          explanation  \\\n",
      "protein_name                                                                                            \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...  Corrosion relevance (41.7) | Metal interaction...   \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...  Corrosion relevance (38.8) | Metal interaction...   \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...  Corrosion relevance (39.0) | Metal interaction...   \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...  Corrosion relevance (39.5) | Metal interaction...   \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...  Corrosion relevance (39.5) | Metal interaction...   \n",
      "\n",
      "                                                                                        Sites  \n",
      "protein_name                                                                                   \n",
      "ferredoxin---nad+ reductase; ferredoxin-nicotin...                           [site_1, site_8]  \n",
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-...                                  [site_40]  \n",
      "aspartate transaminase; glutamic-oxaloacetic tr...           [site_6, site_4, site_1, site_8]  \n",
      "phosphoenolpyruvate carboxykinase [ (pep carbox...                          [site_1, site_40]  \n",
      "beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp...  [site_4, site_1, site_6, site_8, site_11]  \n"
     ]
    }
   ],
   "source": [
    "# First, establish the descriptors and categorical descriptors\n",
    "categorical_descriptors = ['protein_name', 'genera', 'functional_categories', 'niche_pathways', \n",
    "                         'enzyme_class', 'corrosion_mechanisms', 'explanation', 'Sites']\n",
    "numerical_descriptors = ['genera_count', 'combined_score']\n",
    "\n",
    "# 1. Create the protein_descriptors dataframe\n",
    "# Start with the columns we need\n",
    "protein_descriptors_raw = protein_hierarchy[categorical_descriptors + numerical_descriptors].copy()\n",
    "\n",
    "# Define custom aggregation functions for different column types\n",
    "def agg_lists(x):\n",
    "    # If already a list, flatten and get unique items\n",
    "    if isinstance(x.iloc[0], list):\n",
    "        flattened = []\n",
    "        for item in x:\n",
    "            if isinstance(item, list):\n",
    "                flattened.extend(item)\n",
    "            else:\n",
    "                flattened.append(item)\n",
    "        # Convert items to strings to make them hashable, then back to list\n",
    "        return list(set([str(i) for i in flattened]))\n",
    "    # If not a list but we want a list of unique values\n",
    "    else:\n",
    "        return list(set([str(i) for i in x]))\n",
    "\n",
    "def agg_first(x):\n",
    "    return x.iloc[0]\n",
    "\n",
    "# Create aggregation dictionary\n",
    "agg_dict = {\n",
    "    'combined_score': 'mean',\n",
    "    'genera_count': 'sum'  # Sum genera_count as requested\n",
    "}\n",
    "\n",
    "# Specify aggregation method for each descriptor column\n",
    "for col in categorical_descriptors:\n",
    "    if col != 'protein_name':  # Skip the groupby column\n",
    "        if col in ['genera', 'Sites']:  # Columns that should be lists of unique values\n",
    "            agg_dict[col] = agg_lists\n",
    "        else:  # Columns where we just want the first value\n",
    "            agg_dict[col] = agg_first\n",
    "\n",
    "# Group by protein_name and aggregate\n",
    "protein_descriptors = protein_descriptors_raw.groupby('protein_name').agg(agg_dict)\n",
    "protein_descriptors = protein_descriptors.sort_values(by='combined_score', ascending=False).head(50)\n",
    "\n",
    "print(protein_descriptors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_descriptors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the protein_nn dataframe\n",
    "# First, get the required columns\n",
    "protein_nn_columns = ['Sites', 'Category', 'protein_name', 'norm_abund_contri',\n",
    "                     'fold_change_2vs1', 'log2fc_2vs1', 'fold_change_3vs2',\n",
    "                     'log2fc_3vs2', 'fold_change_3vs1', 'log2fc_3vs1',\n",
    "                     'specificity', 'prevalence', 'max_abs_log2fc', 'combined_score']\n",
    "\n",
    "protein_nn_raw = protein_hierarchy[protein_nn_columns].copy()\n",
    "\n",
    "# Since we need Sites as the index and protein_names as columns,\n",
    "# with norm_abund_contri as values, we'll pivot the dataframe\n",
    "protein_nn_pivoted = protein_nn_raw.pivot_table(\n",
    "    index='Sites',\n",
    "    columns='protein_name',\n",
    "    values='norm_abund_contri',\n",
    "    aggfunc='mean'  # In case there are multiple entries for the same Site-protein combination\n",
    ")\n",
    "\n",
    "# If you also need the Category for each Site, preserve it\n",
    "site_categories = protein_nn_raw[['Sites', 'Category']].drop_duplicates().set_index('Sites')\n",
    "\n",
    "# Merge the Category back into the pivoted dataframe\n",
    "protein_nn = protein_nn_pivoted.copy()\n",
    "protein_nn = protein_nn.join(site_categories)\n",
    "\n",
    "# Move Category to the beginning of the dataframe\n",
    "category_col = protein_nn.pop('Category')\n",
    "protein_nn.insert(0, 'Category', category_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068db7e",
   "metadata": {},
   "source": [
    "# 4. Novel Candidates\n",
    "During the statistical feature analysis in Notebook 3, several bacterial genera were identified that showed strong correlations with the high-risk corrosion failure category. This led to hypothesize the potential of  of this microorganisms to be associated with corrosion processes and which were not previously documented.\n",
    "In Notebook 4, we conducted a comprehensive literature review using academic databases to investigate the bacterial genera. The findings confirmed that these microorganisms have no prior documentation in scientific literature linking them to corrosion-related processes.\n",
    "Now, we aim to deploy the analyze_protein_hierarchy function to examine whether these bacteria express proteins that are known to induce or accelerate corrosion. This analysis will help determine if these genera possess the molecular machinery to contribute to corrosion despite their absence from corrosion-related literature, potentially identifying novel microbial contributors to corrosion processes that have been overlooked in previous research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c39264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4312/3615788638.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  protein_df['pathway_cluster'] = clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>genera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enoyl-[ reductase [ (ec 1.3.1.9)</td>\n",
       "      <td>[Mycoplana]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d-aspartate ligase (ec 6.3.1.12)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tagatose-bisphosphate aldolase; d-tagatose-1,6...</td>\n",
       "      <td>[Bulleidia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thiosulfate-dehydrogenase (quinone); thiosulfa...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cholesterol oxidase (ec 1.1.3.6) 5.3.3.1) (cho...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chloramphenicol acetyltransferase (ec 2.3.1.28)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>endo-alpha-n-acetylgalactosaminidase (ec 3.2.1...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2,3-dihydro-2,3-dihydroxybenzoate-dehydrogenas...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2,3-dihydroxybenzoate-amp ligase (ec 2.7.7.58)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>selenide, water dikinase; selenophosphate-synt...</td>\n",
       "      <td>[Oxalobacteraceae_unclassified]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        protein_name  \\\n",
       "0                   enoyl-[ reductase [ (ec 1.3.1.9)   \n",
       "1                   d-aspartate ligase (ec 6.3.1.12)   \n",
       "2  tagatose-bisphosphate aldolase; d-tagatose-1,6...   \n",
       "3  thiosulfate-dehydrogenase (quinone); thiosulfa...   \n",
       "4  cholesterol oxidase (ec 1.1.3.6) 5.3.3.1) (cho...   \n",
       "5    chloramphenicol acetyltransferase (ec 2.3.1.28)   \n",
       "6  endo-alpha-n-acetylgalactosaminidase (ec 3.2.1...   \n",
       "7  2,3-dihydro-2,3-dihydroxybenzoate-dehydrogenas...   \n",
       "8     2,3-dihydroxybenzoate-amp ligase (ec 2.7.7.58)   \n",
       "9  selenide, water dikinase; selenophosphate-synt...   \n",
       "\n",
       "                            genera  \n",
       "0                      [Mycoplana]  \n",
       "1                      [Oerskovia]  \n",
       "2                      [Bulleidia]  \n",
       "3                      [Oerskovia]  \n",
       "4                      [Oerskovia]  \n",
       "5                      [Oerskovia]  \n",
       "6                      [Oerskovia]  \n",
       "7                      [Oerskovia]  \n",
       "8                      [Oerskovia]  \n",
       "9  [Oxalobacteraceae_unclassified]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary of genera identified as nobel on Notebook 4.\n",
    "new_genera= ['Oxalobacteraceae_unclassified', 'Oxobacter', 'Mycoplana', 'Bulleidia',  'Oerskovia']\n",
    "new_genera_df = balanced_markers[balanced_markers[\"Genus\"].isin(new_genera)]\n",
    "protein_candidates_markers = analyze_protein_hierarchy_rf(new_genera_df, n_estimators=100, n_top_proteins=5, random_state=42)\n",
    "protein_candidates_markers[[\"protein_name\", \"genera\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cf3f5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['enoyl-[ reductase [ (ec 1.3.1.9)',\n",
       "       '3-oxoacyl-[ reductase (ec 1.1.1.100)',\n",
       "       'enoyl-[ reductase (nadph, si-specific); acyl-acp-dehydrogenase',\n",
       "       'glutathione hydrolase proenzyme (ec 2.3.2.2) 3.4.19',\n",
       "       'beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp-synthase',\n",
       "       '3-oxoacyl-[ synthase 2 (ec 2.3.1.179)',\n",
       "       \"holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7) (4'\",\n",
       "       'aspartate--ammonia ligase (ec 6.3.1.1) (asparagine',\n",
       "       'metal-dependent carboxypeptidase (ec 3.4.17.19)'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary of the protein that were found top on the identified genera to see if these candidate bacteria\n",
    "# also express that ones.\n",
    "top_protein= ['3-oxoacyl', 'enoyl', 'beta-ketoacyl', 'glutathione', 'holo', 'aspartate', 'trna (guanine',\n",
    "              'metal-dependent', 'ferredoxin', 'siroheme-synthase']\n",
    "\n",
    "# Creating a condition that checks if protein_name starts with any of the strings on top protein\n",
    "starts_with_condition = new_genera_df[\"protein_name\"].str.lower().apply(\n",
    "    lambda x: any(x.startswith(tp.lower())for tp in top_protein))\n",
    "#Apply condition to filter the df\n",
    "top_protein_in_new = new_genera_df[starts_with_condition]\n",
    "top_protein_in_new[\"protein_name\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c2eeb",
   "metadata": {},
   "source": [
    "# 5. File Integration of Microbiological Data and Physicochemical Data\n",
    "df_physicochemical comprises the selected features phychem_features and the whole set of parameters if necesary for plotting purposes.\n",
    "The df_micro is the df of protein-genus features selected from the notebook 7_visual_proteins_ipnyb\n",
    "micro_usuals is a dictionary with the list of proven bacteria influencing corrosion and could serve as label for plotting purposes\n",
    "micro_markers is the dictionary with the list of bacteria belonging to the df_micro dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5ac79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_physicochemical = Path(\"/home/beatriz/MIC/1_Physicochemical/Data/\")\n",
    "physichem_path = data_physicochemical /\"Physicochemical.xlsx\"\n",
    "\n",
    "all_physicochemical = pd.read_excel(physichem_path, sheet_name='all_physicochemical', engine ='openpyxl')\n",
    "metadata = pd.read_excel(physichem_path, sheet_name='Metadata', engine ='openpyxl')\n",
    "\n",
    "\n",
    "physichem_features = ['Temperature', 'Type', 'EC_M', 'O2_Eh',\n",
    "                     'Ox_Fe_Zn', 'Cl_SO4_NO3', 'Na_K','pH_HPO4',\n",
    "                       'Ca_HCO3_Mg', 'Cu_Al_Mn', 'Ni_Cr_Mo']\n",
    "physichem_df = all_physicochemical[physichem_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_df= pd.read_excel(markers_path, sheet_name='protein_markers',  engine ='openpyxl')\n",
    "all_physichem = pd.read_excel(markers_path, sheet_name='all_physicochemical', engine ='openpyxl')\n",
    "genus_site_df = pd.read_excel(markers_path, sheet_name='genus_to_sites', engine ='openpyxl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5418bc3",
   "metadata": {},
   "source": [
    "Validation\n",
    "As a first approximation I will take the first 20 with best score, but I will have to iterate through the list and check if these proteins are really relevant to corrosion states or are also found on the other part of the community the other 800 bacteria and if so what is the numerical diffence, if as I think these are universal proteins and belong infact also to the other part of the community, then we have to discard them and found the ones that really make a difference on the failed systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc09ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33351487",
   "metadata": {},
   "source": [
    "# 5. Proteins Associated with Corrosion from the Literature\n",
    "In this section a querry to the group balanced markers is done with the aim to find the following proteins which have been associated with corrosion in the literature\n",
    "all_physiche balanced_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a024a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(r,r)-butanediol-dehydrogenase-meso-butanediol-dehydrogenase: Pseudarthrobacter\n",
      "enoyl-[ reductase (nadph, si-specific); acyl-acp-dehydrogenase: Gallionella\n",
      "isocitrate-dehydrogenase [ (ec 1.1.1.42): Gallionella\n",
      "2-iminoacetate-synthase (ec 4.1.99.19) ([ hydrogenase: Clostridium\n",
      "(r,r)-butanediol-dehydrogenase; butyleneglycol-dehydrogenase;: Paracoccus\n",
      "saccharopine-dehydrogenase (nad+, l-lysine-forming: Desulfobulbus\n",
      "(s,s)-butanediol-dehydrogenase; l-butanediol-dehydrogenase;: Porphyrobacter\n",
      "meso-butanediol-dehydrogenase-(s,s)-butanediol-dehydrogenase: Variovorax\n",
      "cytochrome-c3 hydrogenase; h2:ferricytochrome c3 oxido: Desulfobacterium\n",
      "glycerol-3-phosphate-dehydrogenase (ec 1.1.5.3): Phreatobacter\n",
      "nadph-dehydrogenase (ec 1.6.99.1): Bacillus\n",
      "ferredoxin hydrogenase; h2 oxidizing hydrogenase; h2: Hydrogenophaga\n",
      "2-oxoisovalerate-dehydrogenase subunit alpha (ec 1: Blastomonas\n",
      "polyvinylalcohol-dehydrogenase (ec 1.1.2.6): Bradyrhizobium\n",
      "decarboxylase-oxoglutarate-dehydrogenase thiamine pyrophosphate: Corynebacterium\n",
      "thiosulfate-dehydrogenase (quinone); thiosulfate:quinone: Oerskovia\n",
      "glutamate-dehydrogenase-leucine-dehydrogenase (ec 1: Porphyrobacter\n",
      "l-carnitine-dehydrogenase (cdh) (l-cdh) (ec 1.1.1.108: Halomonas\n",
      "3(or 17)beta-hydroxysteroid-dehydrogenase; beta-hydroxy: Ralstonia\n",
      "hydrogen-dehydrogenase (nadp+); nadp+-linked hydrogenase;: Wchb1-05\n",
      "r,r-butanediol-dehydrogenase-diacetyl-reductase (ec: Neisseria\n",
      "butanediol-dehydrogenase (ec 1.1.1.4) (zinc-binding: Neisseria\n",
      "serine 3-dehydrogenase (nadp+); serine 3-dehydrogenase: Sphingopyxis\n",
      "3-hydroxy acid-dehydrogenase; ydfg (gene name); ymr226c: Enhydrobacter\n",
      "isocitrate-dehydrogenase (ec 1.1.1.41): Pseudoalteromonas\n",
      "sorbitol-dehydrogenase (ec 1.1.99.21): Halomonas\n",
      "3-alpha-(or 20-beta)-hydroxysteroid-dehydrogenase: Sphingobium\n",
      "hydroxybenzaldehyde-dehydrogenase (ec 1.2.1.28): Ralstonia\n",
      "udp-n-acetyl-d-glucosamine 6-dehydrogenase (ec 1.1: Syntrophus\n",
      "sulfite-dehydrogenase (ec 1.8.2.1): Dechloromonas\n",
      "acetaldehyde-dehydrogenase (acetylating); aldehyde: Psb-m-3\n",
      "2,3-dihydro-2,3-dihydroxybenzoate-dehydrogenase (ec: Oerskovia\n",
      "protoporphyrinogen ix-dehydrogenase [ (ec 1.3.5.3): Shewanella\n",
      "benzaldehyde-dehydrogenase (nad) (ec 1.2.1.28): Pseudoxanthomonas\n",
      "uronate-dehydrogenase; uronate:nad-oxido-reductase;: Hydrogenophaga\n",
      "sorbitol-6-phosphate 2-dehydrogenase (ec 1.1.1.140: Enterococcus\n",
      "3,4-dehydroadipyl-coa semialdehyde-dehydrogenase (nadp+: Beta_proteobacterium\n",
      "glutamate-dehydrogenase [; glutamic-dehydrogenase;: Dechloromonas\n",
      "d-arabinitol 4-dehydrogenase; d-arabitol-dehydrogenase;: Hydrogenophaga\n",
      "erythronate-4-phosphate-dehydrogenase (ec 1.1.1.290: Prevotella\n",
      "formaldehyde-dehydrogenase mscr, nad-mycothiol-dependent: Brevibacterium\n",
      "hydrogenase (acceptor) (ec 1.12.99.6): Hydrogenophaga\n",
      "cytochrome-c3 hydrogenase; h2:ferricytochrome c3 oxido: Desulfobacterium\n",
      "cytochrome c-552 (ec 1.7.2.2) (ammonia-forming c nitrite: Shewanella\n",
      "glycosyltransferase (ec 2.4.1.57): Corynebacterium\n",
      "glycosyltransferase (ec 2.4.1.208): Erysipelothrix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define search terms for each protein group - using partial matches rather than just startswith\n",
    "protein_search_terms = {\n",
    "    'hydrogenase': ['hydrogenase', '[nife]', '[fefe]', 'fe-only hydrogenase', 'ni-fe hydrogenase'],\n",
    "    'cytochrome': ['cytochrome c', 'c-type cytochrome', 'cytc'],\n",
    "    'sulfite_reductase': ['dissimilatory sulfite reductase', 'dsrab', 'dsr', 'sulfite reductase'],\n",
    "    'metal_resistance': ['cobalt-zinc-cadmium resistance', 'czca', 'metal efflux', 'metal resistance'],\n",
    "    'quorum_sensing': ['ahl synthase', 'luxi', 'luxr', 'autoinducer synthase', 'quorum sensing'],\n",
    "    'eps_production': ['glycosyltransferase', 'eps synthase', 'exopolysaccharide']\n",
    "}\n",
    "\n",
    "# Function to check if protein name contains any of the search terms\n",
    "def matches_protein_group(protein_name, search_terms):\n",
    "    protein_name_lower = protein_name.lower()\n",
    "    return any(term.lower() in protein_name_lower for term in search_terms)\n",
    "\n",
    "# Create dictionaries to store results\n",
    "found_proteins = {category: [] for category in protein_search_terms}\n",
    "\n",
    "# Search for proteins in each category\n",
    "for category, terms in protein_search_terms.items():\n",
    "    # Create condition that checks if protein_name contains any of the search terms\n",
    "    match_condition = balanced_markers[\"protein_name\"].apply(\n",
    "        lambda x: matches_protein_group(x, terms)\n",
    "    )\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    matched_proteins = balanced_markers[match_condition]\n",
    "    \n",
    "    # Store results\n",
    "    found_proteins[category] = matched_proteins\n",
    "    for protein_name in matched_proteins[\"protein_name\"].unique():\n",
    "        # Get the genera for this protein\n",
    "        protein_rows = matched_proteins[matched_proteins['protein_name'] == protein_name]\n",
    "        genera_value = protein_rows['Genus'].iloc[0]\n",
    "        \n",
    "        # Check if the genera is already a list or a string representation of a list\n",
    "        if isinstance(genera_value, list):\n",
    "            genera_list = genera_value\n",
    "        else:\n",
    "            # Try to evaluate as a Python list if it's a string representation\n",
    "            import ast\n",
    "            try:\n",
    "                genera_list = ast.literal_eval(genera_value)\n",
    "            except:\n",
    "                # If it's just a single string, wrap it in a list\n",
    "                genera_list = [genera_value]\n",
    "        \n",
    "        # Print the protein name and joined genera\n",
    "        print(f\"{protein_name}: {', '.join(genera_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb63da",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (3515341291.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mwith pd.ExcelWriter(combined_path, mode=\"a\", engine='openpyxl') , if_sheet_exists=\"replace\") as writer:\u001b[39m\n                                                                                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(combined_path, mode=\"a\", engine='openpyxl') , if_sheet_exists=\"replace\" as writer:\n",
    "    protein_markers.to_excel(writer, sheet_name= \"protein_markers\", index=True, freeze_panes=(1,0))\n",
    "    all_physicochemical.to_excel(writer, sheet_name= \"all_physicochemical\", index=True, freeze_panes=(1,0))\n",
    "    metadata.to_excel(writer, sheet_name= \"Metadata\", index=True, freeze_panes=(1,0))\n",
    "    protein_candidates.to_excel(writer, sheet_name= \"candidates\", index=True, freeze_panes=(1,0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_Combined Environment",
   "language": "python",
   "name": "combined_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
