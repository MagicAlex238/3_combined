{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f36d6a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a547a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Data processing and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Local\n",
    "base_dir = Path(\"/home/beatriz/MIC/3_combined/data\")\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "markers_path = base_dir /\"combined_markers.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecf64e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local (VSCode) environment\n"
     ]
    }
   ],
   "source": [
    "# Deciding which environment\n",
    "if Path(\"/kaggle\").exists():\n",
    "    print(\"Running in Kaggle environment\")\n",
    "    # For Kaggle work# Input datasets (read-only in Kaggle) # Files in small input directory\n",
    "    base_dir = Path(\"/kaggle/input\")  \n",
    "    abundance_excel = base_dir / \"new-picrust/merged_to_sequence.xlsx\" # inside input small sizes input\n",
    "    #Input market groups\n",
    "    market_dir = base_dir / \"markers\"\n",
    "    # Output dirs\n",
    "    output_base = Path(\"/kaggle/working/\")\n",
    "    # Save the present working data\n",
    "    combined_path = output_base /\"combined_markers.xlsx\"\n",
    "    #Directory to keep  Results\n",
    "    share_dir = output_base/\"Visualisations\"\n",
    "    shared_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "else:\n",
    "    print(\"Running in local (VSCode) environment\")\n",
    "    base_dir = Path(\"data\")\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Base Paths for local environment\n",
    "    abundance_excel = base_dir / \"merged_to_sequence.xlsx\"\n",
    "    # This files are too large for github and are store on Kaggle for educational purposes\n",
    "    output_large = Path(\"/home/beatriz/MIC/output_large\")\n",
    "    #Input market groups\n",
    "    market_dir = output_large / \"markers.parquet/\"  # Directory\n",
    "    output_base = base_dir \n",
    "    #Directory to keep some Results\n",
    "    shared_dir= Path(\"/home/beatriz/SharedFolder/Visualisations/\")\n",
    "    combined_path = base_dir / \"combined_markers.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc808b5",
   "metadata": {},
   "source": [
    "### Importing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf81ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd6535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecb8fa97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913c83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_df = micro_df.sort_values(by='score_combined', ascending=False).head(20)\n",
    "micro_df = micro_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec7e91",
   "metadata": {},
   "source": [
    "# Metodology of the NN\n",
    "Data Collection and Preparation\n",
    "Environmental physicochemical measurements (pH, electrical conductivity [EC], redox potential [Eh]) were obtained for 66 samples, classified into three corrosion categories (Category 1: n = 18; Category 2: n = 32; Category 3: n = 16). Microbiological profiling yielded normalized protein‐abundance contributions (norm_abund_contri) for 70 samples; only samples with matching physicochemical data (n = 66) were retained for modeling.\n",
    "\n",
    "Feature Engineering was done on the previous repository 1_physicochemical with aprox 8 notebooks for the physicochemical features which allows to bring with, several crafted features that have meaningful chemical and phisical explanation. \n",
    "From the microbiological dataset, feature engineering was done on previous repository 2_Micro with approx 6 notebooks. After analysis it was concluded that the best representative combined features from the genera side was no a list of genera but the proteins that express the most of the genera, proteins highly scored as corrosion forming as per our corrosion scoring system. The top N proteins were brough with information on combined_score, abundance, specificity and prevalence. For each sample, a wide‐format matrix was constructed via pivoting such that each chosen protein became a column, populated by its normalized abundance; missing values were imputed as zero. The physicochemical features for instance pH, EC, Eh, etc, were joined on sample identifiers to produce the final feature set:\n",
    "\n",
    "[pH, EC, Eh, Protein₁_abund, Protein₂_abund, …, Protein_N_abund]\n",
    "\n",
    "Each numeric feature was standardized to zero mean and unit variance.\n",
    "\n",
    "Neural Network Architecture\n",
    "A simple feed‐forward neural network was implemented in Python using pytorch. (The local system capacity is no capable to install tensorflow nor keras).\n",
    "The model comprised:\n",
    "\n",
    "    Input layer of size (3 + N)\n",
    "\n",
    "    One hidden Dense layer (64 units, ReLU activation)\n",
    "\n",
    "    Output layer with softmax activation for three‐class classification\n",
    "\n",
    "Dropout (rate = 0.3) was applied after the hidden layer to mitigate overfitting.\n",
    "\n",
    "Model Training and Evaluation\n",
    "Given the limited sample size (n = 66), stratified 5‐fold cross‐validation was used to estimate generalization performance. In each fold:\n",
    "\n",
    "    The network was trained for up to 100 epochs with early stopping (patience = 10) monitoring validation loss.\n",
    "\n",
    "    Categorical cross‐entropy loss and the Adam optimizer (learning rate = 0.001) were employed.\n",
    "\n",
    "    The primary evaluation metric was classification accuracy; secondary metrics included macro‐averaged F₁‐score and area under the receiver‐operating‐characteristic curve (AUROC).\n",
    "\n",
    "Feature‐Selection Experiments\n",
    "To assess the utility of additional protein‐level descriptors (e.g. combined_score, specificity, prevalence, max_abs_log₂ fold‐change), ablation studies were conducted. In each experiment, one descriptor was appended to the abundance features, and cross‐validation accuracy was compared against the baseline model. Features that did not yield a ≥1% improvement in mean accuracy were excluded from the final model.\n",
    "\n",
    "Software and Reproducibility\n",
    "All analyses were performed in Python 3.11. Key libraries included pandas for data manipulation, scikit-learn for preprocessing and cross-validation utilities, and Pytorch for neural‐network modeling. The full code and data preprocessing pipeline are available in the supplementary materials.\n",
    "\n",
    "    Note: Given the modest sample size, model complexity was intentionally constrained to reduce overfitting risk. Future work will explore larger datasets and more expressive architectures.\n",
    "\n",
    "Justification for the independient studies carried out in repository 1_physicochemical and repository 2_Micro\n",
    "\n",
    "By first developing biological and physicochemical markers in isolation, it was ensured that each set of features “stands on its own.” That is if both domains independently flag the same samples as outliers or predictors, that concordance is stronger evidence than any single model could provide .\n",
    "\n",
    "Late fusion preserves interpretability, that is why care have been taken regarding reducing the features and preservind interpretability. In order to quantify agreement a test via Cohen’s κ for discrete labels evaluates if combining actually improves performance or simply introduces noise .\n",
    "\n",
    "The approach is similar to multiple “weak” learners (physics-chem model, biology-protein model) whose consensus is often more reliable than any one alone . If they agree on a sample’s class or outlier status, the statistical confidence is better, if they disagree, those samples become prime candidates for further investigation.\n",
    "\n",
    "This was also justified because of the modest sample size, normally nobody would consider ML on such size of samples. With only ~66 physicochemical and ~70 biological profiles, joint modeling from the outset might have risked overfitting. Building simpler, domain-specific models first lets validate each on its own before adding dimensionality.\n",
    "Crafting meaningful features avoids “black‐box” transformations like PCA that can obscure interpretability.\n",
    "A way to prove additional to Cohen's k test for aggrement evaluation, Bland–Altman plots allows to visualize biases between model predictions. If agreement is high (κ > 0.6 or correlation > 0.7), it would be demonstrated cross-domain validity. If it’s low, the discrepancies themselves are biologically interesting—pointing to conditions where the physicochemical environment and microbial activity diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66a00f7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_combined_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m corr = \u001b[43mdf_combined_features\u001b[49m.corr()[top_features].loc[\u001b[33m\"\u001b[39m\u001b[33mO2_Eh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpH_PO4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFe_Zn_Ox\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df_combined_features' is not defined"
     ]
    }
   ],
   "source": [
    "corr = df_combined_features.corr()[top_features].loc[\"O2_Eh\", \"pH_PO4\", \"Fe_Zn_Ox\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a654e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e9e3f0",
   "metadata": {},
   "source": [
    "## Data Splitting Strategy\n",
    "\n",
    "To ensure robust feature engineering and prevent data leakage, a portion of the data will be reserved for final model validation. The split must preserve the distribution of key factors affecting corrosion mechanisms:\n",
    "\n",
    "1. **Corrosion Severity Label (Primary)** - Ensures balanced representation of corrosion levels and Essential for model evaluation across all severity classes\n",
    "\n",
    "2. **Material Composition**: Different materials exhibit distinct corrosion mechanisms\n",
    "\n",
    "3. **System Temperature Regime** Hot/Cold/Combined systems affect: Reaction kinetics, oxygen solubility, protective film formation, mineral precipitation tendencies\n",
    "\n",
    "4. **Geographical Location**: Influences water chemistry through<. Different treatment regulations (chlorine vs. non-chlorine), regional geological variations in mineral content, country-specific water quality standards\n",
    "\n",
    "5. **System Age (Secondary)**: Collection period: 2014-2018, while potentially relevant for corrosion progression it is considered less critical due to varying maintenance histories and treatment variations make precise temporal effects difficult to isolate\n",
    "\n",
    "This stratified splitting approach ensures the test set remains representative while maintaining the independence necessary for valid model evaluation.\n",
    "The get_material_group from the 5_EDA notebook on the repository 1_physicochemical is replicated here for educational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_material_group(df, material_column='Material'):\n",
    "    \"\"\"\n",
    "    Groups materials based on cluster analysis findings and material properties.\n",
    "    \n",
    "    Key groupings:  - Galvanized Carbon Steel\n",
    "                    - Stainless Steel and Galvanized Variants\n",
    "                    - Copper and Steel Group\n",
    "                    - High-EC Galvanized Variants\n",
    "                    - Plastic-Composite Materials\n",
    "    \n",
    "    Parameters:     df : pandas.DataFrame  Input DataFrame containing material information\n",
    "    material_column : str, default='Material'  Name of the column containing material names\n",
    "        \n",
    "    Returns: pandas.DataFrame with added 'material_group' column\n",
    "    \"\"\"\n",
    "    # Create a copy of the material column to avoid modifying the original\n",
    "    materials = df[material_column].copy()\n",
    "    grouped_materials = []\n",
    "    \n",
    "    for material in materials:\n",
    "        # Standardize material name: convert to string, lowercase, and strip spaces\n",
    "        material_lower = str(material).lower().strip()\n",
    "        \n",
    "        # Group 1: Galvanized Carbon Steel\n",
    "        if material_lower == 'galvanized carbon steel':\n",
    "            grouped_materials.append('Galvanized_Carbon_Steel')\n",
    "            \n",
    "        # Group 2: Stainless Steel and Galvanized Variants\n",
    "        elif material_lower == 'stainless steel' or material_lower == 'galvanized steel_a' or material_lower == 'galvanized steel_b' or material_lower == 'galvanized steel_h':\n",
    "            grouped_materials.append('Stainless_Galvanized')\n",
    "            \n",
    "        # Group 3: Copper and Steel Group\n",
    "        elif material_lower == 'cooper' or material_lower == 'steel' or material_lower == 'cross-linked polyethylene':\n",
    "            grouped_materials.append('Copper_Steel')\n",
    "            \n",
    "        # Group 4: High-EC Galvanized Variants\n",
    "        elif material_lower == 'galvanized steel_i' or material_lower == 'galvanized steel/plastic':\n",
    "            grouped_materials.append('Galvanized')\n",
    "            \n",
    "        # Group 5: Plastic-Composite Materials\n",
    "        elif material_lower == 'galvanized carbon steel/plastic' or material_lower == 'galvanized steel_g' or material_lower == 'galvanized steel_l' or material_lower == 'galvanized steel_u' or material_lower == 'tinplate high-strength plastic':\n",
    "            grouped_materials.append('Plastic_Composite')\n",
    "            \n",
    "        # Catch any other unhandled materials\n",
    "        else:\n",
    "            grouped_materials.append('Other')\n",
    "    \n",
    "    # Add the grouped materials as a new column\n",
    "    df['material_group'] = grouped_materials\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_grouped = get_material_group(df_materials, material_column='Material') # Material Class do no have Material column\n",
    "#the indexes will be kept same as the whole df\n",
    "def create_stratification_groups_v2(row):\n",
    "    \"\"\"\n",
    "    Create comprehensive stratification groups\n",
    "    \"\"\"\n",
    "    # Water treatment regime based on country\n",
    "    water_regime = 'chlorine' if row['Country'] in ['Belgium', 'Netherlands'] else 'no_chlorine' \n",
    "    \n",
    "    # Create stratification group string\n",
    "    strat_group = f\"{row['material_group']}_{water_regime}_label{row['Label']}\" # _{row['Type']}_ I removed the Type condition because it divides the samples in too many classes. \n",
    "    \n",
    "    return strat_group  \n",
    "\n",
    "def split_dataset_v2(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split dataset while maintaining distributions of key features and original indeces\n",
    "    \"\"\"\n",
    "    #Creating a split column with default value, so the spliting can be applied to other dataframe\n",
    "    df['split'] = 'train' # as default value\n",
    "    \n",
    "    # Add material group column\n",
    "    df = get_material_group(df)\n",
    "    #reindexing \n",
    "    df.index = original_indices\n",
    "    # Create stratification groups\n",
    "    df['strat_group'] = df.apply(create_stratification_groups_v2, axis=1)\n",
    "    \n",
    "    # Identify groups with sufficient samples\n",
    "    group_counts = df['strat_group'].value_counts()\n",
    "    large_groups = group_counts[group_counts >= 4].index\n",
    "    small_groups = group_counts[group_counts < 4].index\n",
    "    \n",
    "    # Split data based on group size\n",
    "    large_data = df[df['strat_group'].isin(large_groups)]\n",
    "    small_data = df[df['strat_group'].isin(small_groups)]\n",
    "    \n",
    "    if len(large_data) > 0:\n",
    "        # Stratified split for large groups\n",
    "        train_large_idx, test_large_idx = train_test_split(\n",
    "            large_data.index,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=large_data['strat_group']\n",
    "        )\n",
    "        \n",
    "        if len(small_data) > 0:\n",
    "            train_small_idx, test_small_idx = train_test_split(\n",
    "                small_data.index,\n",
    "                test_size=test_size,\n",
    "                random_state=random_state,\n",
    "                stratify=small_data['strat_group']\n",
    "            )\n",
    "            # Combine indices\n",
    "            train_idx = np.concatenate([train_large_idx, train_small_idx])\n",
    "            test_idx = np.concatenate([test_large_idx, test_small_idx])\n",
    "            \n",
    "        else:  # This else belongs to the small_data if\n",
    "            train_idx = train_large_idx\n",
    "            test_idx = test_large_idx\n",
    "    else:  # This else belongs to the large_data if\n",
    "        # Simple split if no large groups\n",
    "        train_idx, test_idx = train_test_split(\n",
    "            df.index,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    \n",
    "    # Mark split in original dataframe\n",
    "    df.loc[test_idx, 'split'] = 'test'\n",
    "    \n",
    "    # Return train and test dataframes with original indices\n",
    "    return df[df['split'] == 'train'], df[df['split'] == 'test']\n",
    "    \n",
    "def analyze_split_results(train_df, test_df, original_df):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of features in the split datasets\n",
    "    \"\"\"\n",
    "    print(\"=== Split Size Analysis ===\")\n",
    "    print(f\"Total samples: {len(original_df)}\")\n",
    "    print(f\"Training samples: {len(train_df)} ({len(train_df)/len(original_df)*100:.1f}%)\")\n",
    "    print(f\"Test samples: {len(test_df)} ({len(test_df)/len(original_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Analyze distributions\n",
    "    features = ['Material', 'Country', 'Label']\n",
    "    \n",
    "    for feature in features:\n",
    "        print(f\"\\n=== {feature} Distribution ===\")\n",
    "        \n",
    "        # Calculate distributions\n",
    "        train_dist = train_df[feature].value_counts(normalize=True)\n",
    "        test_dist = test_df[feature].value_counts(normalize=True)\n",
    "        original_dist = original_df[feature].value_counts(normalize=True)\n",
    "        \n",
    "        # Combine into a DataFrame\n",
    "        dist_df = pd.DataFrame({\n",
    "            'Original %': original_dist * 100,\n",
    "            'Train %': train_dist * 100,\n",
    "            'Test %': test_dist * 100,\n",
    "            'Original Count': original_df[feature].value_counts(),\n",
    "            'Train Count': train_df[feature].value_counts(),\n",
    "            'Test Count': test_df[feature].value_counts()\n",
    "        }).round(2)\n",
    "        \n",
    "        print(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d6404",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Meta_Split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m grouped_materials_df = get_material_group(\u001b[43mdf_Meta_Split\u001b[49m, material_column=\u001b[33m'\u001b[39m\u001b[33mMaterial\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Apply the split\u001b[39;00m\n\u001b[32m      3\u001b[39m train_df, test_df = split_dataset_v2(grouped_materials_df)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_Meta_Split' is not defined"
     ]
    }
   ],
   "source": [
    "grouped_materials_df = get_material_group(df_Meta_Split, material_column='Material')\n",
    "# Apply the split\n",
    "train_df, test_df = split_dataset_v2(grouped_materials_df)\n",
    "# Analyzing the results\n",
    "analyze_split_results(train_df, test_df, grouped_materials_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c06d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now applying the split to original dataframe\n",
    "split_mapping = grouped_materials_df['split']\n",
    "original['split'] = original.index.map(split_mapping)\n",
    "\n",
    "# Get train and test sets for original dataframe\n",
    "original_train = original[original['split'] == 'train']\n",
    "original_test = original[original['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify indices match\n",
    "print(\"Train indices match:\", set(train_df.index) == set(original_train.index))\n",
    "print(\"Test indices match:\", set(test_df.index) == set(original_test.index))\n",
    "print(\"No overlap between train and test:\", len(set(train_df.index) & set(test_df.index)) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we assigne the original_train set to the dataframe to work in this notebook moving forward and we keep the original_test df to work for the model validation\n",
    "df = original_train.drop(columns=['split']).copy() # .drop(columns=['Label']).values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a5d80",
   "metadata": {},
   "source": [
    "The initial strategy for dataset partitioning aimed to ensure a balanced representation across Location, Material, Type, and Label variables. Despite implementing sophisticated preprocessing steps - including hierarchical cluster analysis for material grouping and stratification of locations based on Cl- treatment protocols - the limited sample size (n=13) proved insufficient relative to the number of distinct classes, preventing a statistically valid split.\n",
    "\n",
    "To address this limitation, Type was removed from the stratification criteria. This decision was supported by two key analytical findings:\n",
    "\n",
    "Principal Component Analysis (PCA) in three dimensions demonstrated strong clustering patterns based on materials and locations alone, suggesting these features effectively capture the underlying data structure.\n",
    "\n",
    "Feature importance analysis using XGBoost revealed that Composition accounts for approximately 50% of the variance in material type distribution across clusters, indicating that material properties are inherently captured through compositional data.\n",
    "\n",
    "This modification to the stratification approach maintains the essential patterns in the data while enabling a more robust train-test split for subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel = df[top_features]\n",
    "y = df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or softmax for >2 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cef101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_37861/169521571.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Data preparation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m X_sel = \u001b[43mdf\u001b[49m[top_features]\n\u001b[32m     10\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mCategory\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Data preparation\n",
    "X_sel = df[top_features]\n",
    "y = df['Category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values)\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 32)\n",
    "        self.layer2 = nn.Linear(32, 16)\n",
    "        self.layer3 = nn.Linear(16, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = SimpleNN(input_size)\n",
    "print(f\"Model created with input size: {input_size}\")\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with smaller batches\n",
    "num_epochs = 10\n",
    "batch_size = 8  # Small batch size for memory efficiency\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Use smaller batches to reduce memory usage\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        # Get batch\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size].view(-1, 1)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / (len(X_train) / batch_size)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Evaluate every epoch to track progress\n",
    "    if (epoch + 1) % 2 == 0:  # Check every 2 epochs\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_test_tensor)\n",
    "            y_pred_class = (y_pred > 0.5).float()\n",
    "            accuracy = (y_pred_class.view(-1) == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "            print(f'Validation Accuracy after epoch {epoch+1}: {accuracy:.4f}')\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "    accuracy = (y_pred_class.view(-1) == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "    print(f'Final Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # Print predictions for first few samples\n",
    "    for i in range(min(5, len(y_test))):\n",
    "        print(f\"Sample {i+1}: Actual: {y_test.iloc[i]}, Predicted: {y_pred[i].item():.4f}, Class: {y_pred_class[i].item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_Combined Environment",
   "language": "python",
   "name": "combined_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
