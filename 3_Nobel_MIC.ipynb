{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f36d6a4",
   "metadata": {},
   "source": [
    "# Nobel Microorganisms Influencing Corrosion\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "__Inverse Patterns - Protective Bacteria?__\n",
    "During the statistical analysis notebook 3, important patterns emerged with some bacteria especially persistent on the normal operation systems this is the less affected by corrosion systems, therefore it was teoritized that some of those could be producing metabolites that inhibith corrosion. Hereby this inverse patterns are studied. Studies had shown that some compounds reported to produce inhibition of corrosion. Those compounds could be sintetised by some bacteria, and for that to occur some enzymes are required, only the bacteria with those enzymes are able to sintetise such compounds. The second part of this notebook would engage with investigating the enzymes present on those inverse_results to see if some of them are possible on the duty of inhibit corrosion or are simple bacteria that happend to be on the environment without being involve on any corrosion bussiness. Notably bacteria phenil  is present,  Phenylalanine and related compounds (like some phenolic acids) have been studied for their corrosion inhibition properties. The bacteria producing these compounds could be offering a natural corrosion protection mechanism. This is similar to how certain biofilms can sometimes act as a protective barrier rather than accelerating corrosion.\n",
    "For your protective factor analysis, I would recommend:\n",
    "\n",
    "Extract proteins from the inverse pattern bacteria that are associated with:\n",
    "\n",
    "Amino acid biosynthesis (particularly aromatic amino acids like phenylalanine, tyrosine, tryptophan)\n",
    "EPS (extracellular polymeric substance) production\n",
    "Production of siderophores (which can complex with iron and potentially reduce corrosion)\n",
    "Organic acid metabolism (some can form protective films)\n",
    "Proteins involved in oxygen consumption (creating less oxidizing conditions)\n",
    "\n",
    "\n",
    "Compare protein profiles between sites with different corrosion rates - sites with lower corrosion might have higher abundance of these protective proteins\n",
    "Look for proteins involved in antagonistic relationships with known corrosion-promoting bacteria\n",
    "\n",
    "The idea of finding proteins that synthesize protective compounds is excellent. You could specifically search for proteins in pathways like:\n",
    "\n",
    "Shikimate pathway (leads to aromatic amino acids)\n",
    "Phenylpropanoid metabolism\n",
    "Polyamine synthesis\n",
    "Certain secondary metabolite pathways\n",
    "\n",
    "__Novel Candidates Microorganisms Inducint Corrosion__\n",
    "During the statistical feature analysis in Notebook 3, several bacterial genera were identified that showed strong correlations with the high-risk corrosion failure category. This led to hypothesize the potential of  of this microorganisms to be associated with corrosion processes and which were not previously documented.\n",
    "In Notebook 4, we conducted a comprehensive literature review using academic databases to investigate the bacterial genera. The findings confirmed that these microorganisms have no prior documentation in scientific literature linking them to corrosion-related processes.\n",
    "Now, we aim to deploy the analyze_protein_hierarchy function to examine whether these bacteria express proteins that are known to induce or accelerate corrosion. This analysis will help determine if these genera possess the molecular machinery to contribute to corrosion despite their absence from corrosion-related literature, potentially identifying novel microbial contributors to corrosion processes that have been overlooked in previous research.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c120c3",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a547a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_12813/143084480.py\", line 19, in <module>\n",
      "    import torch\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/beatriz/MIC/3_combined/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Data processing and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Standard library imports\n",
    "import ast\n",
    "import subprocess\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import re\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.metrics import silhouette_score\n",
    "from kneed import KneeLocator\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import to_rgba, LinearSegmentedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import kaleido\n",
    "\n",
    "# Machine learning and statistical analysis\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import umap\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import spearmanr, kruskal, mannwhitneyu\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import shap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "# Utility libraries\n",
    "import gzip\n",
    "import random\n",
    "from natsort import natsorted\n",
    "from typing import Dict, List, Tuple, Set, Optional\n",
    "import gc\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "\n",
    "# Dash\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, callback, State\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Own Scoring system\n",
    "import corrosion_scoring as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca72e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local (VSCode) environment\n"
     ]
    }
   ],
   "source": [
    "# Determine the environment\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Running in Google Colab environment\")\n",
    "    # for colab\n",
    "    base_dir = Path(\"/content/drive/MyDrive/MIC\")\n",
    "    abundance_excel = base_dir / \"data_picrust/merged_to_sequence.xlsx\"\n",
    "    output_large = base_dir / \"output_large\"\n",
    "    output_base = base_dir\n",
    "    market_dir = base_dir / \"output_large\" \n",
    "    #Directory to keep some Results\n",
    "    large_dir = base_dir / \"2_Micro/data_visual\"\n",
    "    large_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "elif Path(\"/kaggle\").exists():\n",
    "    print(\"Running in Kaggle environment\")\n",
    "    # For Kaggle work# Input datasets (read-only in Kaggle) \n",
    "    base_dir = Path(\"/kaggle/input/\")  \n",
    "    abundance_excel = base_dir / \"new-picrust/merged_to_sequence.xlsx\" \n",
    "    #Input physicochemical variables\n",
    "    data_physicochemical = base_dir / \"physicochemical-parameters/Physicochemical.xlsx\"\n",
    "    combined_input = base_dir  / \"combined_markers.xlsx\"\n",
    "    #===============================================\n",
    "    #Directory to keep  Results\n",
    "    output_base = Path(\"/kaggle/working/\")\n",
    "    shared_dir = output_base/\"Visualisations\"\n",
    "    shared_dir.mkdir(parents=True, exist_ok=True)\n",
    "    combined_path = output_base / \"combined_markers.xlsx\"\n",
    "      \n",
    "else:\n",
    "    print(\"Running in local (VSCode) environment\")\n",
    "    base_dir = Path(\"data\")\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Base Paths for local environment\n",
    "    abundance_excel = base_dir / \"merged_to_sequence.xlsx\"\n",
    "    #Input physicochemical variables8ikk                           ´\n",
    "    data_physicochemical = Path(\"/home/beatriz/MIC/1_Physicochemical/Data/Physicochemical.xlsx\")\n",
    "    #================================================\n",
    "    # This files are too large for github and are store on Kaggle for educational purposes\n",
    "    output_large = Path(\"/home/beatriz/MIC/output_large\")\n",
    "    output_base = base_dir \n",
    "    #Directory to keep some Results\n",
    "    shared_dir= Path(\"/home/beatriz/SharedFolder/Visualisations/\")\n",
    "    combined_path = base_dir / \"combined_markers.xlsx\"\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc808b5",
   "metadata": {},
   "source": [
    "### Importing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf81ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physicochemical data data from notebook 8 repo 1_Physicochemical\n",
    "all_physichem = pd.read_excel(data_physicochemical, sheet_name='all_physicochemical', engine ='openpyxl')\n",
    "# Microbiological Data from notebook 6 repo 2_Micro.\n",
    "inverse_df = pd.read_excel(combined_path, sheet_name='df_proteins',  engine ='openpyxl')\n",
    "#mapping of genera to site from the original df for validation\n",
    "genus_site_df = pd.read_excel(combined_path, sheet_name='genus_to_sites', engine ='openpyxl')\n",
    "# All markers after pattern, integration, classification, increasing, and balance functions\n",
    "balanced_markers= pd.read_excel(combined_path, sheet_name='balanced_markers', engine ='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040495c",
   "metadata": {},
   "source": [
    "# 3. Inverse Patterns - Protective Bacteria?\n",
    "\n",
    "inverse patterns are collected on inverse_df, so the idea is to rejoin this part of the data at the end of the analysis to reconstruct the whole data and in doing so have an equal representation of the classes. Otherwise the data would have only class 2 and 3 since the pipeline main aim is to filter our the data. Never the less down the pipeline other 3 sites are lost to balance representation function and because of those belong to the increasing results, it is better to rejoin on the missing sites from classified_markers. That is in order to have a comprehensive class representation for the final Neuro Network. On the other hand the Inverse Pattern contain on inverse_results would also be brough forward to analyse wether some of the enzymes are related to known inhibitors to corrosion failure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068db7e",
   "metadata": {},
   "source": [
    "# 4. Novel Candidates Microorganisms Inducint Corrosion \n",
    "During the statistical feature analysis in Notebook 3, several bacterial genera were identified that showed strong correlations with the high-risk corrosion failure category. This led to hypothesize the potential of  of this microorganisms to be associated with corrosion processes and which were not previously documented.\n",
    "In Notebook 4, we conducted a comprehensive literature review using academic databases to investigate the bacterial genera. The findings confirmed that these microorganisms have no prior documentation in scientific literature linking them to corrosion-related processes.\n",
    "Now, we aim to deploy the analyze_protein_hierarchy function to examine whether these bacteria express proteins that are known to induce or accelerate corrosion. This analysis will help determine if these genera possess the molecular machinery to contribute to corrosion despite their absence from corrosion-related literature, potentially identifying novel microbial contributors to corrosion processes that have been overlooked in previous research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5580/2573382650.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  protein_df['pathway_cluster'] = clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>genera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enoyl-[ reductase [ (ec 1.3.1.9)</td>\n",
       "      <td>[Mycoplana]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d-aspartate ligase (ec 6.3.1.12)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tagatose-bisphosphate aldolase; d-tagatose-1,6...</td>\n",
       "      <td>[Bulleidia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thiosulfate-dehydrogenase (quinone); thiosulfa...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cholesterol oxidase (ec 1.1.3.6) 5.3.3.1) (cho...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chloramphenicol acetyltransferase (ec 2.3.1.28)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>endo-alpha-n-acetylgalactosaminidase (ec 3.2.1...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2,3-dihydro-2,3-dihydroxybenzoate-dehydrogenas...</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2,3-dihydroxybenzoate-amp ligase (ec 2.7.7.58)</td>\n",
       "      <td>[Oerskovia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>selenide, water dikinase; selenophosphate-synt...</td>\n",
       "      <td>[Oxalobacteraceae_unclassified]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        protein_name  \\\n",
       "0                   enoyl-[ reductase [ (ec 1.3.1.9)   \n",
       "1                   d-aspartate ligase (ec 6.3.1.12)   \n",
       "2  tagatose-bisphosphate aldolase; d-tagatose-1,6...   \n",
       "3  thiosulfate-dehydrogenase (quinone); thiosulfa...   \n",
       "4  cholesterol oxidase (ec 1.1.3.6) 5.3.3.1) (cho...   \n",
       "5    chloramphenicol acetyltransferase (ec 2.3.1.28)   \n",
       "6  endo-alpha-n-acetylgalactosaminidase (ec 3.2.1...   \n",
       "7  2,3-dihydro-2,3-dihydroxybenzoate-dehydrogenas...   \n",
       "8     2,3-dihydroxybenzoate-amp ligase (ec 2.7.7.58)   \n",
       "9  selenide, water dikinase; selenophosphate-synt...   \n",
       "\n",
       "                            genera  \n",
       "0                      [Mycoplana]  \n",
       "1                      [Oerskovia]  \n",
       "2                      [Bulleidia]  \n",
       "3                      [Oerskovia]  \n",
       "4                      [Oerskovia]  \n",
       "5                      [Oerskovia]  \n",
       "6                      [Oerskovia]  \n",
       "7                      [Oerskovia]  \n",
       "8                      [Oerskovia]  \n",
       "9  [Oxalobacteraceae_unclassified]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Creating a dictionary of genera identified as nobel on Notebook 4.\n",
    "new_genera= ['Oxalobacteraceae_unclassified', 'Oxobacter', 'Mycoplana', 'Bulleidia',  'Oerskovia']\n",
    "new_genera_df = balanced_markers[balanced_markers[\"Genus\"].isin(new_genera)]\n",
    "protein_candidates_markers = analyze_protein_hierarchy_rf(new_genera_df, n_estimators=100, n_top_proteins=5, random_state=42)'''\n",
    "protein_candidates_markers[[\"protein_name\", \"genera\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3f5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['enoyl-[ reductase [ (ec 1.3.1.9)',\n",
       "       '3-oxoacyl-[ reductase (ec 1.1.1.100)',\n",
       "       'enoyl-[ reductase (nadph, si-specific); acyl-acp-dehydrogenase',\n",
       "       'glutathione hydrolase proenzyme (ec 2.3.2.2) 3.4.19',\n",
       "       'beta-ketoacyl-[ synthase iii (beta-ketoacyl-acp-synthase',\n",
       "       '3-oxoacyl-[ synthase 2 (ec 2.3.1.179)',\n",
       "       \"holo-[ synthase (holo-acp-synthase) (ec 2.7.8.7) (4'\",\n",
       "       'aspartate--ammonia ligase (ec 6.3.1.1) (asparagine',\n",
       "       'metal-dependent carboxypeptidase (ec 3.4.17.19)'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary of the protein that were found top on the identified genera to see if these candidate bacteria\n",
    "# also express that ones.\n",
    "top_protein= ['3-oxoacyl', 'enoyl', 'beta-ketoacyl', 'glutathione', 'holo', 'aspartate', 'trna (guanine',\n",
    "              'metal-dependent', 'ferredoxin', 'siroheme-synthase']\n",
    "\n",
    "# Creating a condition that checks if protein_name starts with any of the strings on top protein\n",
    "starts_with_condition = new_genera_df[\"protein_name\"].str.lower().apply(\n",
    "    lambda x: any(x.startswith(tp.lower())for tp in top_protein))\n",
    "#Apply condition to filter the df\n",
    "top_protein_in_new = new_genera_df[starts_with_condition]\n",
    "top_protein_in_new[\"protein_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc09ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb63da",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (3515341291.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mwith pd.ExcelWriter(combined_path, mode=\"a\", engine='openpyxl') , if_sheet_exists=\"replace\") as writer:\u001b[39m\n                                                                                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(combined_path, mode=\"a\", engine='openpyxl') , if_sheet_exists=\"replace\" as writer:\n",
    "    protein_markers.to_excel(writer, sheet_name= \"protein_markers\", index=True, freeze_panes=(1,0))\n",
    "    all_physicochemical.to_excel(writer, sheet_name= \"all_physicochemical\", index=True, freeze_panes=(1,0))\n",
    "    metadata.to_excel(writer, sheet_name= \"Metadata\", index=True, freeze_panes=(1,0))\n",
    "    protein_candidates.to_excel(writer, sheet_name= \"candidates\", index=True, freeze_panes=(1,0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_Combined Environment",
   "language": "python",
   "name": "combined_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
